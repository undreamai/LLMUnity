### ðŸš€ Features

- VisionOS support (PR: #299)
- Upgrade LlamaLib to v1.2.4 (llama.cpp b4969) (PR: #325)
- Add support for Gemma 3 and Phi 4 models (PR: #327)
- Default number of predicted tokens (num_predict) to infinity (-1) (PR: #328)

