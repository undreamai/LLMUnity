<!-- HTML header for doxygen 1.9.1-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.10.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>LLM for Unity: Overview</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link rel="shortcut icon" href="logo_tiny.png" type="image/png">
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<!-- ... other metadata & script includes ... -->
<script type="text/javascript" src="doxygen-awesome-fragment-copy-button.js"></script>
<script type="text/javascript" src="doxygen-awesome-darkmode-toggle.js"></script>
<script type="text/javascript" src="doxygen-awesome-paragraph-link.js"></script>
<script type="text/javascript" src="doxygen-awesome-interactive-toc.js"></script>
<script type="text/javascript">
    DoxygenAwesomeFragmentCopyButton.init()
    DoxygenAwesomeDarkModeToggle.init()
    DoxygenAwesomeParagraphLink.init()
    DoxygenAwesomeInteractiveToc.init()
</script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="doxygen-awesome.css" rel="stylesheet" type="text/css"/>
<link href="custom.css" rel="stylesheet" type="text/css"/>
<link href="doxygen-awesome-sidebar-only.css" rel="stylesheet" type="text/css"/>
<link href="doxygen-awesome-sidebar-only-darkmode-toggle.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<!-- https://tholman.com/github-corners/ -->
<a href="https://github.com/undreamai/LLMUnity" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="logo_tiny.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">LLM for Unity
   &#160;<span id="projectnumber">v3.0.2</span>
   </div>
   <div id="projectbrief">Create characters in Unity with LLMs!</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.10.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){initNavTree('index.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">Overview </div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a class="anchor" id="md_README"></a></p>
<h1 align="center"><img src="images/logo.png" alt="" height="150" class="inline"/>  </h1>
<h3 align="center">Create characters in Unity with LLMs!</h3>
<p><a href="https://opensource.org/license/apache-2-0"><img src="https://img.shields.io/badge/License-Apache_2.0-yellow.svg" alt="License: Apache" style="pointer-events: none;" class="inline"/></a> <a href="https://discord.gg/RwXKQb6zdv"><img src="https://discordapp.com/api/guilds/1194779009284841552/widget.png?style=shield" alt="" class="inline"/></a> <a href="https://www.reddit.com/user/UndreamAI"><img src="https://img.shields.io/badge/Reddit-%23FF4500.svg?style=flat&amp;logo=Reddit&amp;logoColor=white" alt="Reddit" style="pointer-events: none;" class="inline"/></a> <a href="https://www.linkedin.com/company/undreamai"><img src="https://img.shields.io/badge/LinkedIn-blue?style=flat&amp;logo=linkedin&amp;labelColor=blue" alt="LinkedIn" class="inline"/></a> <a href="https://assetstore.unity.com/packages/slug/273604"><img src="https://img.shields.io/badge/Asset%20Store-black.svg?style=flat&amp;logo=unity" alt="Asset Store" style="pointer-events: none;" class="inline"/></a> <a href="https://github.com/undreamai/LLMUnity"><img src="https://img.shields.io/github/stars/undreamai/LLMUnity?style=flat&amp;logo=github&amp;color=f5f5f5" alt="GitHub Repo stars" class="inline"/></a> <a href="https://undream.ai/LLMUnity"><img src="https://img.shields.io/badge/Docs-white.svg?logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwEAYAAAAHkiXEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABl0RVh0U29mdHdhcmUAd3d3Lmlua3NjYXBlLm9yZ5vuPBoAAATqSURBVHic7ZtbiE1RGMc349K4M5EwklwjzUhJCMmTJPJAYjQXJJcH8+Blkry4lPJA8aAoJbekDLmUS6E8SHJL5AW5JPf77eHv93C22Wfttc/ee+0zc/4vv+bMXvusvfZa3/q+b33H80oqqaSSSmqrKnPdgXjUvbvYq5f4+7f486eb/rRajRsn7t4tPngg/vol/vkj/vghXr0q7tghzpyZ//79+on79omXLombNondukXrd9GoSxdx8mSxqUm8eVNkgAvl0aPioEFip07i6dP52z15Ig4fbvVY2VVFhbhokXjrlogJiWvAg/jwoXjqVO73+leUny9eiFVV5mfMlLDRBw+KX76ISQ+0LZ8/F00v4uJFsWPHFh83O+rdWzx3TnQ9wCZ+/Sqyl5iux1RmTu3aiYcPi64H1pasALypoOv4/8SJXraEbXc9kLbECxo2TKyuFj9/zt9u+XIvG8LWv3wpuh5QW86f3/JznT+fv93s2S23C1Z72wbhtH692LdvMvdPSgzkhAkiJhT16ZO/PRPOmcr+Rda4aa5nclTeuZP7PDgRpr1g40bPrQYOFF0PYKHEC+raVVy8OFy7R49EArvURU4mrUAqaTY0iB8/2rXD+XCm5mbR9QAWylevorV7/VpkL0ld06eLpkiyWPj9u93179+LpFZwZ1PXtGnitWui64GMStPmG7SH1NSIJBNHjvTSFZvRvHlise0N9JcBtW1/44Y4dqx45IjnU0JxAGLpklPx+9VZFwPp/9v/eZDGjxcZh7dv4+mXtch+up7Rca+MsJvxiRNi6nvBhg25HWprZMaPGeOlqxEjxGKz+XGRTAAmyJnq6sR370TXA2NLW+8HNjZ62dLOnaLrAQ1r2zmqPH482n0mTfJCKmEvCJHUooNZE/369Elct06kqiKsONRfulTEFDsX8QDlIa5nup9374pE8IiZHPY+ly+LZE/37/cM6mC6IB6Vl4urV6fzfUG6d0/csyf37wsXRFInaM4ckTjGdPg+apTYs6dI3RIWwH//1DV1qkiuxNY2FzrTd+2y6y8z2HQU6efZs+KBAyJZ4v+V0h6ArlwROaQP0uPH4ooV4sqV8Xz/4MF211M2wwoOq1mzRAq5Pnywa5+4KDHE9mI7ly0TO3fOvZ6/eZCoKwB32HS0SMFV1DNtImBKHYstBROoQ4fEQk2RaS+qrxejmj5M7NatIhWARS82xUJfAKahzFcdPnq0GLYgy7Rnbd8e6rGKRyzpuNzPBQty709RcNSZf/KkuHCh2GpMDyKbGNcLYE+YMkVks336NFx7XhTZ3szXiBaqtWvFuAOxM2dEZiyH8UErgc8JLNun7E0aFffSI7RP6owZmz9kSO73HjsmXr8ukppYsybSYyQvBp5QfOjQ3M9tRR496pGgLf1JtLlzRZJzlFzGp4SWDnUxFCrdvy+uWiWa3DJe3N69oj8uSEq8CER88uaNOGBAOv2ILGY69TBBJoM8O0t72zaRoztXBzlLlrT8XARW/IQq82JTMv3mKmv0/9CC4mJMYPwrMSETxAyurRUxQVmXP1fEid7mzeK3b+n2Jzb16CFu2SIWmtNJiriVxANsyq0uoCJfTk4G9y4t24/bSQ0rTkP6gVTG3mz//uKMGSK/ucId5Xe9lZUi5eMMLGUgz56J5Hxu3xZ50Xg3RMIltVn9BRja26PYsBHgAAAAAElFTkSuQmCC" alt="Documentation" style="pointer-events: none;" class="inline"/></a></p>
<p>LLM for Unity enables seamless integration of Large Language Models (LLMs) within the Unity engine.<br  />
 It allows to create intelligent AI characters that players can interact with for an immersive experience.<br  />
 The package includes a Retrieval-Augmented Generation (RAG) system for semantic search across your data, which can be used to enhance the character's knowledge.<br  />
</p>
<p>The LLM backend, <a href="https://github.com/undreamai/LlamaLib">LlamaLib</a>, is built on top of the awesome <a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a> library and provided as a standalone C++/C# library.</p>
<h1><a class="anchor" id="autotoc_md1"></a>
At a glance</h1>
<ul>
<li>üíª Runs anywhere: PC, mobile or VR!</li>
<li>‚ö° Blazing fast inference on CPU and GPU (Nvidia, AMD, Apple Metal)</li>
<li>üè† Runs locally without internet access. No data ever leave your game!</li>
<li>üì° Supports remote server setup</li>
<li>ü§ó Supports all major LLM models</li>
<li>üîç Advanced RAG System (ANN search)</li>
<li>üîß Easy to setup, call with a single line of code</li>
<li>üí∞ Free to use for both personal and commercial purposes</li>
</ul>
<p>üß™ Tested on Unity: 2021 LTS, 2022 LTS, 2023, Unity 6<br  />
 üö¶ <a href="https://github.com/orgs/undreamai/projects/2/views/10">Upcoming Releases</a></p>
<h2><a class="anchor" id="autotoc_md2"></a>
Business inquiries</h2>
<p>For business inquiries you can reach out at <a href="#" onclick="location.href='mai'+'lto:'+'hel'+'lo'+'@un'+'dr'+'eam'+'.a'+'i'; return false;">hello<span class="obfuscator">.nosp@m.</span>@und<span class="obfuscator">.nosp@m.</span>ream.<span class="obfuscator">.nosp@m.</span>ai</a>.</p>
<h1><a class="anchor" id="autotoc_md3"></a>
How to help</h1>
<ul>
<li><a href="https://github.com/undreamai/LLMUnity">‚≠ê Star</a> the repo, leave a <a href="https://assetstore.unity.com/packages/slug/273604">review</a> and spread the word about the project!</li>
<li>Join us at <a href="https://discord.gg/RwXKQb6zdv">Discord</a> and say hi.</li>
<li>Contribute by submitting feature requests, bugs or even your own PR.</li>
<li><a href="https://github.com/sponsors/amakropoulos"><img src="https://img.shields.io/static/v1?label=Sponsor&amp;message=%E2%9D%A4&amp;logo=GitHub&amp;color=%23fe8e86" alt="" class="inline"/></a> this work or buy me a <a href="https://ko-fi.com/amakropoulos"><img src="https://img.shields.io/badge/Ko--fi-FF5E5B?logo=ko-fi&amp;logoColor=white" alt="Ko-fi" class="inline"/></a> to allow even cooler features!</li>
</ul>
<h1><a class="anchor" id="autotoc_md4"></a>
Games / Projects using LLM for Unity</h1>
<ul>
<li><a href="https://store.steampowered.com/app/2778780/Verbal_Verdict/">Verbal Verdict</a></li>
<li><a href="https://store.epicgames.com/de/p/i-chatbot-aisylum-83b2b5">I, Chatbot: AISYLUM</a></li>
<li><a href="https://unicorninteractive.itch.io/nameless-souls-of-the-void">Nameless Souls of the Void</a></li>
<li><a href="https://roadedlich.itch.io/murder-in-aisle-4">Murder in Aisle 4</a></li>
<li><a href="https://helixngc7293.itch.io/finicky-food-delivery-ai">Finicky Food Delivery AI</a></li>
<li><a href="https://whynames.itch.io/aiemotionalgirlfriend">AI Emotional Girlfriend</a></li>
<li><a href="https://store.steampowered.com/app/2532160/Case_Closed">Case Closed</a></li>
<li><a href="https://github.com/IhateCreatingUserNames2/MaiMai">MaiMai AI Agent System</a></li>
<li><a href="https://play.google.com/store/apps/details?id=com.ProLink.ClariaChat">Claria Chat</a></li>
<li><a href="https://store.steampowered.com/app/2928500/Endless_Casual_Drive/">Endless Casual Drive</a></li>
<li><a href="https://store.steampowered.com/app/3415680/Dating_App_Simulator/">Dating App Simulator</a></li>
<li><a href="https://vrmi.vercel.app/">Virtual Reality Mock Interview</a></li>
<li><a href="https://github.com/Velesio/Velesio-AIServer">Velesio AI server</a></li>
<li><a href="https://www.meta.com/experiences/dungeonchat/8527310950709276/">Dungeon Chat</a></li>
<li><a href="https://joycatdev.itch.io/tomonaka-desk">Tomonaka Desk</a></li>
<li><a href="https://store.steampowered.com/app/3089280/Digital_Humans/">Digital Humans</a></li>
<li><a href="https://ripenedpeach.itch.io/cakemix">CakeMix</a></li>
<li><a href="https://squirclegames.itch.io/hey-waifu-ai">HeyWaifu</a></li>
<li><a href="https://store.steampowered.com/app/3886140/Love_and_Lie/">Love and Lie</a></li>
<li><a href="https://store.steampowered.com/app/1244620/Psycho_Simulator/">Psycho Simulator</a></li>
</ul>
<p>Contact <a href="#" onclick="location.href='mai'+'lto:'+'hel'+'lo'+'@un'+'dr'+'eam'+'.a'+'i'; return false;">hello<span class="obfuscator">.nosp@m.</span>@und<span class="obfuscator">.nosp@m.</span>ream.<span class="obfuscator">.nosp@m.</span>ai</a> to add your project!</p>
<h1><a class="anchor" id="autotoc_md5"></a>
Setup</h1>
<p><em>Method 1: Install using the asset store</em></p><ul>
<li>Open the <a href="https://assetstore.unity.com/packages/slug/273604">LLM for Unity</a> asset page and click <code>Add to My Assets</code></li>
<li>Open the Package Manager in Unity: <code>Window &gt; Package Manager</code></li>
<li>Select the <code>Packages: My Assets</code> option from the drop-down</li>
<li>Select the <code>LLM for Unity</code> package, click <code>Download</code> and then <code>Import</code></li>
</ul>
<p><em>Method 2: Install using the GitHub repo:</em></p><ul>
<li>Open the Package Manager in Unity: <code>Window &gt; Package Manager</code></li>
<li>Click the <code>+</code> button and select <code>Add package from git URL</code></li>
<li>Use the repository URL <code><a href="https://github.com/undreamai/LLMUnity.git">https://github.com/undreamai/LLMUnity.git</a></code> and click <code>Add</code></li>
</ul>
<h1><a class="anchor" id="autotoc_md6"></a>
Quick start</h1>
<p><img src="images/character.png" alt="" height="300" class="inline"/></p>
<h3><a class="anchor" id="autotoc_md7"></a>
1. Setup the LLM</h3>
<p>First you will setup the LLM for your game:</p><ul>
<li>Create an empty GameObject.<br  />
In the GameObject Inspector click <code>Add Component</code> and select the <code>LLM</code> script.</li>
<li>Download one of the default models with the <code>Download Model</code> button (~GBs).<br  />
Or load your own .gguf model with the <code>Load model</code> button (see LLM model management).</li>
</ul>
<h3><a class="anchor" id="autotoc_md8"></a>
2. Create an AI Character</h3>
<p>Then you can setup each of your characters as follows:</p><ul>
<li>Create an empty GameObject for the character.<br  />
In the GameObject Inspector click <code>Add Component</code> and select the <code>LLMAgent</code> script.</li>
<li>Define the role of your AI in the <code>System Prompt</code>.</li>
<li>(Optional) Select the LLM constructed above in the <code>LLM</code> field if you have more than one LLM GameObjects.</li>
</ul>
<h3><a class="anchor" id="autotoc_md9"></a>
3. Use in Your Script</h3>
<p>In your script you can then use it as follows: </p><div class="fragment"><div class="line"><span class="keyword">using </span><a class="code hl_namespace" href="namespaceLLMUnity.html">LLMUnity</a>;</div>
<div class="line"> </div>
<div class="line"><span class="keyword">public</span> <span class="keyword">class </span>MyScript {</div>
<div class="line">  <span class="keyword">public</span> <a class="code hl_class" href="classLLMUnity_1_1LLMAgent.html">LLMAgent</a> llmAgent;</div>
<div class="line">  </div>
<div class="line">  <span class="keywordtype">void</span> HandleReply(<span class="keywordtype">string</span> replySoFar){</div>
<div class="line">    <span class="comment">// do something with the reply from the model as it is being produced</span></div>
<div class="line">    Debug.Log(replySoFar);</div>
<div class="line">  }</div>
<div class="line">  </div>
<div class="line">  <span class="keywordtype">void</span> Game(){</div>
<div class="line">    <span class="comment">// handle the response as it is being produced</span></div>
<div class="line">    ...</div>
<div class="line">    _ = llmAgent.<a class="code hl_function" href="classLLMUnity_1_1LLMAgent.html#ae6c59733400df0e8ab289a91e23eb2ef">Chat</a>(<span class="stringliteral">&quot;Hello bot!&quot;</span>, HandleReply);</div>
<div class="line">    ...</div>
<div class="line">  }</div>
<div class="line">  </div>
<div class="line">  async <span class="keywordtype">void</span> GameAsync(){</div>
<div class="line">    <span class="comment">// or handle the entire response in one go</span></div>
<div class="line">    ...</div>
<div class="line">    <span class="keywordtype">string</span> reply = await llmAgent.<a class="code hl_function" href="classLLMUnity_1_1LLMAgent.html#ae6c59733400df0e8ab289a91e23eb2ef">Chat</a>(<span class="stringliteral">&quot;Hello bot!&quot;</span>);</div>
<div class="line">    Debug.Log(reply);</div>
<div class="line">    ...</div>
<div class="line">  }</div>
<div class="line">}</div>
<div class="ttc" id="aclassLLMUnity_1_1LLMAgent_html"><div class="ttname"><a href="classLLMUnity_1_1LLMAgent.html">LLMUnity.LLMAgent</a></div><div class="ttdoc">Unity MonoBehaviour that implements a conversational AI agent with persistent chat history....</div><div class="ttdef"><b>Definition</b> <a href="LLMAgent_8cs_source.html#l00020">LLMAgent.cs:21</a></div></div>
<div class="ttc" id="aclassLLMUnity_1_1LLMAgent_html_ae6c59733400df0e8ab289a91e23eb2ef"><div class="ttname"><a href="classLLMUnity_1_1LLMAgent.html#ae6c59733400df0e8ab289a91e23eb2ef">LLMUnity.LLMAgent.Chat</a></div><div class="ttdeci">virtual async Task&lt; string &gt; Chat(string query, Action&lt; string &gt; callback=null, Action completionCallback=null, bool addToHistory=true)</div><div class="ttdoc">Processes a user query asynchronously and generates an AI response using conversation context....</div><div class="ttdef"><b>Definition</b> <a href="LLMAgent_8cs_source.html#l00269">LLMAgent.cs:269</a></div></div>
<div class="ttc" id="anamespaceLLMUnity_html"><div class="ttname"><a href="namespaceLLMUnity.html">LLMUnity</a></div><div class="ttdef"><b>Definition</b> <a href="LLM_8cs_source.html#l00012">LLM.cs:13</a></div></div>
</div><!-- fragment --><p> You can also specify a function to call when the model reply has been completed: </p><div class="fragment"><div class="line"><span class="keywordtype">void</span> ReplyCompleted(){</div>
<div class="line">  <span class="comment">// do something when the reply from the model is complete</span></div>
<div class="line">  Debug.Log(<span class="stringliteral">&quot;The AI has finished replying&quot;</span>);</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line"><span class="keywordtype">void</span> Game(){</div>
<div class="line">  <span class="comment">// your game function</span></div>
<div class="line">  ...</div>
<div class="line">  _ = llmAgent.<a class="code hl_function" href="classLLMUnity_1_1LLMAgent.html#ae6c59733400df0e8ab289a91e23eb2ef">Chat</a>(<span class="stringliteral">&quot;Hello bot!&quot;</span>, HandleReply, ReplyCompleted);</div>
<div class="line">  ...</div>
<div class="line">}</div>
</div><!-- fragment --><p>To stop the chat without waiting for its completion you can use: </p><div class="fragment"><div class="line">llmAgent.<a class="code hl_function" href="classLLMUnity_1_1LLMAgent.html#a9f977fb6fa1aac403867b6a650ba23df">CancelRequests</a>();</div>
<div class="ttc" id="aclassLLMUnity_1_1LLMAgent_html_a9f977fb6fa1aac403867b6a650ba23df"><div class="ttname"><a href="classLLMUnity_1_1LLMAgent.html#a9f977fb6fa1aac403867b6a650ba23df">LLMUnity.LLMAgent.CancelRequests</a></div><div class="ttdeci">void CancelRequests()</div><div class="ttdoc">Cancels any active requests for this agent.</div><div class="ttdef"><b>Definition</b> <a href="LLMAgent_8cs_source.html#l00408">LLMAgent.cs:408</a></div></div>
</div><!-- fragment --><ul>
<li>Finally, in the Inspector of the GameObject of your script, select the LLMAgent GameObject created above as the llmAgent property.</li>
</ul>
<p>That's it! Your AI character is ready to chat! ‚ú®</p>
<h1><a class="anchor" id="autotoc_md10"></a>
Advanced usage</h1>
<details >
<summary >
Build a mobile app</summary>
<p></p>
<p>For mobile apps you can use models with up to 1-2 billion parameters ("Tiny models" in the LLM model manager).<br  />
 Larger models will typically not work due to the limited mobile hardware.</p>
<p><b>iOS</b> iOS can be built with the default player settings.</p>
<p><b>Android</b> On Android you need to specify the <code>IL2CPP</code> scripting backend and the <code>ARM64</code> as the target architecture in the player settings.<br  />
 These settings can be accessed from the <code>Edit &gt; Project Settings</code> menu within the <code>Player &gt; Other Settings</code> section.<br  />
 <img src="images/android.png" alt="" width="400" class="inline"/></p>
<p>Since mobile app sizes are typically small, you can download the LLM model the first time the app launches. This functionality is enabled with the <code>Download on Build</code> option. In your project you can wait until the model download is complete with: </p><div class="fragment"><div class="line">await <a class="code hl_class" href="classLLMUnity_1_1LLM.html">LLM</a>.<a class="code hl_function" href="classLLMUnity_1_1LLM.html#a24dd61490ab2510492915d2d5f28f86b">WaitUntilModelSetup</a>();</div>
<div class="ttc" id="aclassLLMUnity_1_1LLM_html"><div class="ttname"><a href="classLLMUnity_1_1LLM.html">LLMUnity.LLM</a></div><div class="ttdoc">Unity MonoBehaviour component that manages a local LLM server instance. Handles model loading,...</div><div class="ttdef"><b>Definition</b> <a href="LLM_8cs_source.html#l00020">LLM.cs:21</a></div></div>
<div class="ttc" id="aclassLLMUnity_1_1LLM_html_a24dd61490ab2510492915d2d5f28f86b"><div class="ttname"><a href="classLLMUnity_1_1LLM.html#a24dd61490ab2510492915d2d5f28f86b">LLMUnity.LLM.WaitUntilModelSetup</a></div><div class="ttdeci">static async Task&lt; bool &gt; WaitUntilModelSetup(Action&lt; float &gt; downloadProgressCallback=null)</div><div class="ttdoc">Waits asynchronously until model setup is complete.</div><div class="ttdef"><b>Definition</b> <a href="LLM_8cs_source.html#l00560">LLM.cs:560</a></div></div>
</div><!-- fragment --><p> You can also receive calls the download progress during the model download: </p><div class="fragment"><div class="line">await <a class="code hl_class" href="classLLMUnity_1_1LLM.html">LLM</a>.<a class="code hl_function" href="classLLMUnity_1_1LLM.html#a24dd61490ab2510492915d2d5f28f86b">WaitUntilModelSetup</a>(SetProgress);</div>
<div class="line"> </div>
<div class="line"><span class="keywordtype">void</span> SetProgress(<span class="keywordtype">float</span> progress){</div>
<div class="line">  <span class="keywordtype">string</span> progressPercent = ((int)(progress * 100)).ToString() + <span class="stringliteral">&quot;%&quot;</span>;</div>
<div class="line">  Debug.Log($<span class="stringliteral">&quot;Download progress: {progressPercent}&quot;</span>);</div>
<div class="line">}</div>
</div><!-- fragment --><p> This is useful to present e.g. a progress bar. The <a href="https://github.com/undreamai/LLMUnity/tree/main/Samples~/MobileDemo">MobileDemo</a> demonstrates an example application for Android / iOS.</p>
<p></p>
</details>
<details >
<summary >
Restrict the output of the LLM / Function calling / Grammar</summary>
<p></p>
<p>To restrict the output of the LLM you can use a grammar, read more <a href="https://github.com/ggerganov/llama.cpp/tree/master/grammars">here</a>.<br  />
 The grammar can edited directly in the <code>Grammar</code> field of the LLMAgent or saved in a gbnf / json schema file and loaded with the <code>Load Grammar</code> button (Advanced options).<br  />
 For instance to receive replies in json format you can use the <a href="https://github.com/ggerganov/llama.cpp/blob/b4218/grammars/json.gbnf">json.gbnf</a> grammar.<br  />
</p>
<p>Alternatively you can set the grammar directly in your script: </p><div class="fragment"><div class="line">llmAgent.grammar = <span class="stringliteral">&quot;your grammar here&quot;</span>;</div>
</div><!-- fragment --><p>For function calling you can define similarly a grammar that allows only the function names as output, and then call the respective function.<br  />
 You can look into the <a href="https://github.com/undreamai/LLMUnity/tree/main/Samples~/FunctionCalling">FunctionCalling</a> sample for an example implementation.</p>
<p></p>
</details>
<details >
<summary >
Access / Save / Load your chat history</summary>
<p>The chat history of a <code>LLMAgent</code> is retained in the <code>chat</code> variable that is a list of <code>ChatMessage</code> objects.<br  />
 The ChatMessage is a class that defines the <code>role</code> of the message and the <code>content</code>.<br  />
 The list contains alternating messages with the player prompt and the AI reply.<br  />
 You can modify the chat history and then set it to your LLMAgent GameObject: </p><div class="fragment"><div class="line">List&lt;ChatMessage&gt; newChat = <span class="keyword">new</span> List&lt;ChatMessage&gt;();</div>
<div class="line">...</div>
<div class="line">llmAgent.chat = newChat;</div>
</div><!-- fragment --><p>To add new messages you can do: </p><div class="fragment"><div class="line">_ = llmAgent.<a class="code hl_function" href="classLLMUnity_1_1LLMAgent.html#a65ab75abb384a56aae64ed771b2025a2">AddUserMessage</a>(<span class="stringliteral">&quot;your user message&quot;</span>);</div>
<div class="line">_ = llmAgent.<a class="code hl_function" href="classLLMUnity_1_1LLMAgent.html#af619217340b1ea39bb293b6fa076b338">AddAssistantMessage</a>(<span class="stringliteral">&quot;your assistant reply&quot;</span>);</div>
<div class="ttc" id="aclassLLMUnity_1_1LLMAgent_html_a65ab75abb384a56aae64ed771b2025a2"><div class="ttname"><a href="classLLMUnity_1_1LLMAgent.html#a65ab75abb384a56aae64ed771b2025a2">LLMUnity.LLMAgent.AddUserMessage</a></div><div class="ttdeci">virtual async Task AddUserMessage(string content)</div><div class="ttdoc">Adds a user message to the conversation history.</div><div class="ttdef"><b>Definition</b> <a href="LLMAgent_8cs_source.html#l00216">LLMAgent.cs:216</a></div></div>
<div class="ttc" id="aclassLLMUnity_1_1LLMAgent_html_af619217340b1ea39bb293b6fa076b338"><div class="ttname"><a href="classLLMUnity_1_1LLMAgent.html#af619217340b1ea39bb293b6fa076b338">LLMUnity.LLMAgent.AddAssistantMessage</a></div><div class="ttdeci">virtual async Task AddAssistantMessage(string content)</div><div class="ttdoc">Adds an AI assistant message to the conversation history.</div><div class="ttdef"><b>Definition</b> <a href="LLMAgent_8cs_source.html#l00226">LLMAgent.cs:226</a></div></div>
</div><!-- fragment --><p>To automatically save / load your chat history, you can specify the <code>Save</code> parameter of the LLMAgent to the filename (or relative path) of your choice. The chat history is saved in the <a href="https://docs.unity3d.com/ScriptReference/Application-persistentDataPath.html">persistentDataPath folder of Unity</a> as a json object.</p>
<p>To manually save your chat history, you can use: </p><div class="fragment"><div class="line">_ = llmAgent.<a class="code hl_function" href="classLLMUnity_1_1LLMAgent.html#a645e508151519ce876ca14b3284c09bd">SaveHistory</a>();</div>
<div class="ttc" id="aclassLLMUnity_1_1LLMAgent_html_a645e508151519ce876ca14b3284c09bd"><div class="ttname"><a href="classLLMUnity_1_1LLMAgent.html#a645e508151519ce876ca14b3284c09bd">LLMUnity.LLMAgent.SaveHistory</a></div><div class="ttdeci">virtual async Task SaveHistory()</div><div class="ttdoc">Saves the conversation history and optionally the LLM cache to disk.</div><div class="ttdef"><b>Definition</b> <a href="LLMAgent_8cs_source.html#l00343">LLMAgent.cs:343</a></div></div>
</div><!-- fragment --><p> and to load the history: </p><div class="fragment"><div class="line">_ = llmAgent.Loadistory();</div>
</div><!-- fragment --><p></p>
</details>
<details >
<summary >
Process the prompt at the beginning of your app for faster initial processing time</summary>
<p></p>
<div class="fragment"><div class="line"><span class="keywordtype">void</span> WarmupCompleted(){</div>
<div class="line">  <span class="comment">// do something when the warmup is complete</span></div>
<div class="line">  Debug.Log(<span class="stringliteral">&quot;The AI is nice and ready&quot;</span>);</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line"><span class="keywordtype">void</span> Game(){</div>
<div class="line">  <span class="comment">// your game function</span></div>
<div class="line">  ...</div>
<div class="line">  _ = llmAgent.<a class="code hl_function" href="classLLMUnity_1_1LLMAgent.html#a0ca59bd1f8e8db1f1e20078bde1f9e20">Warmup</a>(WarmupCompleted);</div>
<div class="line">  ...</div>
<div class="line">}</div>
<div class="ttc" id="aclassLLMUnity_1_1LLMAgent_html_a0ca59bd1f8e8db1f1e20078bde1f9e20"><div class="ttname"><a href="classLLMUnity_1_1LLMAgent.html#a0ca59bd1f8e8db1f1e20078bde1f9e20">LLMUnity.LLMAgent.Warmup</a></div><div class="ttdeci">virtual async Task Warmup(Action completionCallback=null)</div><div class="ttdoc">Warms up the model by processing the system prompt without generating output. This caches the system ...</div><div class="ttdef"><b>Definition</b> <a href="LLMAgent_8cs_source.html#l00308">LLMAgent.cs:308</a></div></div>
</div><!-- fragment --><p></p>
</details>
<details >
<summary >
Decide whether or not to add the message to the chat/prompt history</summary>
<p></p>
<p>The last argument of the <code>Chat</code> function is a boolean that specifies whether to add the message to the history (default: true): </p><div class="fragment"><div class="line"><span class="keywordtype">void</span> Game(){</div>
<div class="line">  <span class="comment">// your game function</span></div>
<div class="line">  ...</div>
<div class="line">  <span class="keywordtype">string</span> message = <span class="stringliteral">&quot;Hello bot!&quot;</span>;</div>
<div class="line">  _ = llmAgent.<a class="code hl_function" href="classLLMUnity_1_1LLMAgent.html#ae6c59733400df0e8ab289a91e23eb2ef">Chat</a>(message, HandleReply, ReplyCompleted, <span class="keyword">false</span>);</div>
<div class="line">  ...</div>
<div class="line">}</div>
</div><!-- fragment --><p></p>
</details>
<details >
<summary >
Use pure text completion</summary>
<p></p>
<div class="fragment"><div class="line"><span class="keywordtype">void</span> Game(){</div>
<div class="line">  <span class="comment">// your game function</span></div>
<div class="line">  ...</div>
<div class="line">  <span class="keywordtype">string</span> message = <span class="stringliteral">&quot;The cat is away&quot;</span>;</div>
<div class="line">  _ = llmAgent.<a class="code hl_function" href="classLLMUnity_1_1LLMClient.html#a028dd1162ec620c842df80631abfa5b2">Completion</a>(message, HandleReply, ReplyCompleted);</div>
<div class="line">  ...</div>
<div class="line">}</div>
<div class="ttc" id="aclassLLMUnity_1_1LLMClient_html_a028dd1162ec620c842df80631abfa5b2"><div class="ttname"><a href="classLLMUnity_1_1LLMClient.html#a028dd1162ec620c842df80631abfa5b2">LLMUnity.LLMClient.Completion</a></div><div class="ttdeci">virtual async Task&lt; string &gt; Completion(string prompt, Action&lt; string &gt; callback=null, Action completionCallback=null, int id_slot=-1)</div><div class="ttdoc">Generates text completion.</div><div class="ttdef"><b>Definition</b> <a href="LLMClient_8cs_source.html#l00579">LLMClient.cs:579</a></div></div>
</div><!-- fragment --><p></p>
</details>
<details >
<summary >
Add a LLM / LLMAgent component programmatically</summary>
<p></p>
<div class="fragment"><div class="line"><span class="keyword">using </span>UnityEngine;</div>
<div class="line"><span class="keyword">using </span><a class="code hl_namespace" href="namespaceLLMUnity.html">LLMUnity</a>;</div>
<div class="line"> </div>
<div class="line"><span class="keyword">public</span> <span class="keyword">class </span>MyScript : MonoBehaviour</div>
<div class="line">{</div>
<div class="line">    <a class="code hl_class" href="classLLMUnity_1_1LLM.html">LLM</a> llm;</div>
<div class="line">    <a class="code hl_class" href="classLLMUnity_1_1LLMAgent.html">LLMAgent</a> llmAgent;</div>
<div class="line"> </div>
<div class="line">    async <span class="keywordtype">void</span> Start()</div>
<div class="line">    {</div>
<div class="line">        <span class="comment">// disable gameObject so that theAwake is not called immediately</span></div>
<div class="line">        gameObject.SetActive(<span class="keyword">false</span>);</div>
<div class="line"> </div>
<div class="line">        <span class="comment">// Add an LLM object</span></div>
<div class="line">        llm = gameObject.AddComponent&lt;<a class="code hl_class" href="classLLMUnity_1_1LLM.html">LLM</a>&gt;();</div>
<div class="line">        <span class="comment">// set the model using the filename of the model.</span></div>
<div class="line">        <span class="comment">// The model needs to be added to the LLM model manager (see LLM model management) by loading or downloading it.</span></div>
<div class="line">        <span class="comment">// Otherwise the model file can be copied directly inside the StreamingAssets folder.</span></div>
<div class="line">        llm.model = <span class="stringliteral">&quot;Qwen3-4B-Q4_K_M.gguf&quot;</span>;</div>
<div class="line">        <span class="comment">// optional: you can also set loras in a similar fashion and set their weights (if needed)</span></div>
<div class="line">        llm.<a class="code hl_function" href="classLLMUnity_1_1LLM.html#aca1105d2114768d8229590043bedae42">AddLora</a>(<span class="stringliteral">&quot;my-lora.gguf&quot;</span>);</div>
<div class="line">        llm.<a class="code hl_function" href="classLLMUnity_1_1LLM.html#aca1105d2114768d8229590043bedae42">AddLora</a>(<span class="stringliteral">&quot;my-lora-2.gguf&quot;</span>, 0.5f);</div>
<div class="line">        <span class="comment">// optional: set number of threads</span></div>
<div class="line">        llm.numThreads = -1;</div>
<div class="line">        <span class="comment">// optional: enable GPU by setting the number of model layers to offload to it</span></div>
<div class="line">        llm.numGPULayers = 10;</div>
<div class="line"> </div>
<div class="line">        <span class="comment">// Add an LLMAgent object</span></div>
<div class="line">        llmAgent = gameObject.AddComponent&lt;<a class="code hl_class" href="classLLMUnity_1_1LLMAgent.html">LLMAgent</a>&gt;();</div>
<div class="line">        <span class="comment">// set the LLM object that handles the model</span></div>
<div class="line">        llmAgent.llm = llm;</div>
<div class="line">        <span class="comment">// set the character prompt</span></div>
<div class="line">        llmAgent.systemPrompt = <span class="stringliteral">&quot;A chat between a curious human and an artificial intelligence assistant.&quot;</span>;</div>
<div class="line">        <span class="comment">// set the AI and player name</span></div>
<div class="line">        llmAgent.assistantRole = <span class="stringliteral">&quot;AI&quot;</span>;</div>
<div class="line">        llmAgent.userRole = <span class="stringliteral">&quot;Human&quot;</span>;</div>
<div class="line">        <span class="comment">// optional: set a save path</span></div>
<div class="line">        llmAgent.save = <span class="stringliteral">&quot;AICharacter1.json&quot;</span>;</div>
<div class="line">        <span class="comment">// optional: set a grammar</span></div>
<div class="line">        llmAgent.grammar = <span class="stringliteral">&quot;your grammar here&quot;</span>;</div>
<div class="line"> </div>
<div class="line">        <span class="comment">// re-enable gameObject</span></div>
<div class="line">        gameObject.SetActive(<span class="keyword">true</span>);</div>
<div class="line">    }</div>
<div class="line">}</div>
<div class="ttc" id="aclassLLMUnity_1_1LLM_html_aca1105d2114768d8229590043bedae42"><div class="ttname"><a href="classLLMUnity_1_1LLM.html#aca1105d2114768d8229590043bedae42">LLMUnity.LLM.AddLora</a></div><div class="ttdeci">void AddLora(string path, float weight=1f)</div><div class="ttdoc">Adds a LORA adapter to the existing set.</div><div class="ttdef"><b>Definition</b> <a href="LLM_8cs_source.html#l00676">LLM.cs:676</a></div></div>
</div><!-- fragment --><p></p>
</details>
<details >
<summary >
Use a remote server</summary>
<p></p>
<p>You can use a remote server to carry out the processing and implement characters that interact with it.</p>
<p><b>Create the server</b><br  />
 To create the server:</p><ul>
<li>Create a project with a GameObject using the <code>LLM</code> script as described above</li>
<li>Enable the <code>Remote</code> option of the <code>LLM</code> and optionally configure the server port and API key</li>
<li>Enable 'Allow Downloads Over HTTP' in the project settings</li>
<li>Build and run to start the server</li>
</ul>
<p>Alternatively you can use a server binary for easier deployment:</p><ul>
<li>Run the above scene from the Editor and copy the command from the Debug messages (starting with "Deploy server command:")</li>
<li>Download and extract the <a href="https://github.com/undreamai/LlamaLib/releases/download/v2.0.0/LlamaLib-v2.0.0.zip">LlamaLib binaries</a></li>
<li>From command line change directory to the <code>servers</code> folder selected and start the server by running the command copied from above.</li>
</ul>
<p><b>Create the characters</b><br  />
 Create a second project with the game characters using the <code>LLMAgent</code> script as described above. Enable the <code>Remote</code> option and configure the host with the IP address (starting with "http://") and port / API key of the server.</p>
<p></p>
</details>
<details >
<summary >
Compute embeddings using a LLM</summary>
<p></p>
<p>The <code>Embeddings</code> function can be used to obtain the emdeddings of a phrase: </p><div class="fragment"><div class="line">List&lt;float&gt; embeddings = await llmAgent.<a class="code hl_function" href="classLLMUnity_1_1LLMClient.html#a4a2e444ff6f9031820cfac4fa3190f52">Embeddings</a>(<span class="stringliteral">&quot;hi, how are you?&quot;</span>);</div>
<div class="ttc" id="aclassLLMUnity_1_1LLMClient_html_a4a2e444ff6f9031820cfac4fa3190f52"><div class="ttname"><a href="classLLMUnity_1_1LLMClient.html#a4a2e444ff6f9031820cfac4fa3190f52">LLMUnity.LLMClient.Embeddings</a></div><div class="ttdeci">virtual async Task&lt; List&lt; float &gt; &gt; Embeddings(string query, Action&lt; List&lt; float &gt; &gt; callback=null)</div><div class="ttdoc">Generates embedding vectors for the input text.</div><div class="ttdef"><b>Definition</b> <a href="LLMClient_8cs_source.html#l00548">LLMClient.cs:548</a></div></div>
</div><!-- fragment --><p></p>
</details>
<p>A <b>detailed documentation</b> on function level can be found here: <a href="https://undream.ai/LLMUnity"><img src="https://img.shields.io/badge/Documentation-white.svg?logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwEAYAAAAHkiXEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABl0RVh0U29mdHdhcmUAd3d3Lmlua3NjYXBlLm9yZ5vuPBoAAATqSURBVHic7ZtbiE1RGMc349K4M5EwklwjzUhJCMmTJPJAYjQXJJcH8+Blkry4lPJA8aAoJbekDLmUS6E8SHJL5AW5JPf77eHv93C22Wfttc/ee+0zc/4vv+bMXvusvfZa3/q+b33H80oqqaSSSmqrKnPdgXjUvbvYq5f4+7f486eb/rRajRsn7t4tPngg/vol/vkj/vghXr0q7tghzpyZ//79+on79omXLombNondukXrd9GoSxdx8mSxqUm8eVNkgAvl0aPioEFip07i6dP52z15Ig4fbvVY2VVFhbhokXjrlogJiWvAg/jwoXjqVO73+leUny9eiFVV5mfMlLDRBw+KX76ISQ+0LZ8/F00v4uJFsWPHFh83O+rdWzx3TnQ9wCZ+/Sqyl5iux1RmTu3aiYcPi64H1pasALypoOv4/8SJXraEbXc9kLbECxo2TKyuFj9/zt9u+XIvG8LWv3wpuh5QW86f3/JznT+fv93s2S23C1Z72wbhtH692LdvMvdPSgzkhAkiJhT16ZO/PRPOmcr+Rda4aa5nclTeuZP7PDgRpr1g40bPrQYOFF0PYKHEC+raVVy8OFy7R49EArvURU4mrUAqaTY0iB8/2rXD+XCm5mbR9QAWylevorV7/VpkL0ld06eLpkiyWPj9u93179+LpFZwZ1PXtGnitWui64GMStPmG7SH1NSIJBNHjvTSFZvRvHlise0N9JcBtW1/44Y4dqx45IjnU0JxAGLpklPx+9VZFwPp/9v/eZDGjxcZh7dv4+mXtch+up7Rca+MsJvxiRNi6nvBhg25HWprZMaPGeOlqxEjxGKz+XGRTAAmyJnq6sR370TXA2NLW+8HNjZ62dLOnaLrAQ1r2zmqPH482n0mTfJCKmEvCJHUooNZE/369Elct06kqiKsONRfulTEFDsX8QDlIa5nup9374pE8IiZHPY+ly+LZE/37/cM6mC6IB6Vl4urV6fzfUG6d0/csyf37wsXRFInaM4ckTjGdPg+apTYs6dI3RIWwH//1DV1qkiuxNY2FzrTd+2y6y8z2HQU6efZs+KBAyJZ4v+V0h6ArlwROaQP0uPH4ooV4sqV8Xz/4MF211M2wwoOq1mzRAq5Pnywa5+4KDHE9mI7ly0TO3fOvZ6/eZCoKwB32HS0SMFV1DNtImBKHYstBROoQ4fEQk2RaS+qrxejmj5M7NatIhWARS82xUJfAKahzFcdPnq0GLYgy7Rnbd8e6rGKRyzpuNzPBQty709RcNSZf/KkuHCh2GpMDyKbGNcLYE+YMkVks336NFx7XhTZ3szXiBaqtWvFuAOxM2dEZiyH8UErgc8JLNun7E0aFffSI7RP6owZmz9kSO73HjsmXr8ukppYsybSYyQvBp5QfOjQ3M9tRR496pGgLf1JtLlzRZJzlFzGp4SWDnUxFCrdvy+uWiWa3DJe3N69oj8uSEq8CER88uaNOGBAOv2ILGY69TBBJoM8O0t72zaRoztXBzlLlrT8XARW/IQq82JTMv3mKmv0/9CC4mJMYPwrMSETxAyurRUxQVmXP1fEid7mzeK3b+n2Jzb16CFu2SIWmtNJiriVxANsyq0uoCJfTk4G9y4t24/bSQ0rTkP6gVTG3mz//uKMGSK/ucId5Xe9lZUi5eMMLGUgz56J5Hxu3xZ50Xg3RMIltVn9BRja26PYsBHgAAAAAElFTkSuQmCC" alt="" style="pointer-events: none;" class="inline"/></a></p>
<h1><a class="anchor" id="autotoc_md11"></a>
Semantic search with a RAG system</h1>
<p>LLM for Unity implements a super-fast similarity search functionality with a Retrieval-Augmented Generation (RAG) system.<br  />
 It is based on the LLM embeddings, and the Approximate Nearest Neighbors (ANN) search from the <a href="https://github.com/unum-cloud/usearch">usearch</a> library.<br  />
 Semantic search works as follows.</p>
<p><b>Building the data</b> You provide text inputs (a phrase, paragraph, document) to add to the data.<br  />
 Each input is split into chunks (optional) and encoded into embeddings with a LLM.</p>
<p><b>Searching</b> You can then search for a query text input. <br  />
 The input is again encoded and the most similar text inputs or chunks in the data are retrieved.</p>
<p>To use semantic serch:</p><ul>
<li>create a GameObject for the LLM as described above. Download one of the provided RAG models or load your own (good options can be found at the <a href="https://huggingface.co/spaces/mteb/leaderboard">MTEB leaderboard</a>).</li>
<li>create an empty GameObject. In the GameObject Inspector click <code>Add Component</code> and select the <code>RAG</code> script.</li>
<li>In the Search Type dropdown of the RAG select your preferred search method. <code>SimpleSearch</code> is a simple brute-force search, while<code>DBSearch</code> is a fast ANN method that should be preferred in most cases.</li>
<li>In the Chunking Type dropdown of the RAG you can select a method for splitting the inputs into chunks. This is useful to have a more consistent meaning within each data part. Chunking methods for splitting according to tokens, words and sentences are provided.</li>
</ul>
<p>Alternatively, you can create the RAG from code (where llm is your LLM): </p><div class="fragment"><div class="line"><a class="code hl_class" href="classLLMUnity_1_1RAG.html">RAG</a> rag = gameObject.AddComponent&lt;<a class="code hl_class" href="classLLMUnity_1_1RAG.html">RAG</a>&gt;();</div>
<div class="line">rag.<a class="code hl_function" href="classLLMUnity_1_1RAG.html#a12f6d0345e9ee76a32b61e5f676fa945">Init</a>(<a class="code hl_enumeration" href="namespaceLLMUnity.html#a57c2884128df2e335455f2ba44e84e46">SearchMethods</a>.DBSearch, <a class="code hl_enumeration" href="namespaceLLMUnity.html#a8901dc84125a5c569f32e9991e846818">ChunkingMethods</a>.SentenceSplitter, llm);</div>
<div class="ttc" id="aclassLLMUnity_1_1RAG_html"><div class="ttname"><a href="classLLMUnity_1_1RAG.html">LLMUnity.RAG</a></div><div class="ttdoc">Class implementing a Retrieval Augmented Generation (RAG) system based on a search method and an opti...</div><div class="ttdef"><b>Definition</b> <a href="RAG_8cs_source.html#l00038">RAG.cs:39</a></div></div>
<div class="ttc" id="aclassLLMUnity_1_1RAG_html_a12f6d0345e9ee76a32b61e5f676fa945"><div class="ttname"><a href="classLLMUnity_1_1RAG.html#a12f6d0345e9ee76a32b61e5f676fa945">LLMUnity.RAG.Init</a></div><div class="ttdeci">void Init(SearchMethods searchMethod=SearchMethods.SimpleSearch, ChunkingMethods chunkingMethod=ChunkingMethods.NoChunking, LLM llm=null)</div><div class="ttdoc">Constructs the Retrieval Augmented Generation (RAG) system based on the provided search and chunking ...</div><div class="ttdef"><b>Definition</b> <a href="RAG_8cs_source.html#l00059">RAG.cs:59</a></div></div>
<div class="ttc" id="anamespaceLLMUnity_html_a57c2884128df2e335455f2ba44e84e46"><div class="ttname"><a href="namespaceLLMUnity.html#a57c2884128df2e335455f2ba44e84e46">LLMUnity.SearchMethods</a></div><div class="ttdeci">SearchMethods</div><div class="ttdoc">Search methods implemented in LLMUnity.</div><div class="ttdef"><b>Definition</b> <a href="RAG_8cs_source.html#l00014">RAG.cs:15</a></div></div>
<div class="ttc" id="anamespaceLLMUnity_html_a8901dc84125a5c569f32e9991e846818"><div class="ttname"><a href="namespaceLLMUnity.html#a8901dc84125a5c569f32e9991e846818">LLMUnity.ChunkingMethods</a></div><div class="ttdeci">ChunkingMethods</div><div class="ttdoc">Chunking methods implemented in LLMUnity.</div><div class="ttdef"><b>Definition</b> <a href="RAG_8cs_source.html#l00025">RAG.cs:26</a></div></div>
</div><!-- fragment --><p>In your script you can then use it as follows :unicorn:: </p><div class="fragment"><div class="line"><span class="keyword">using </span><a class="code hl_namespace" href="namespaceLLMUnity.html">LLMUnity</a>;</div>
<div class="line"> </div>
<div class="line"><span class="keyword">public</span> <span class="keyword">class </span>MyScript : MonoBehaviour</div>
<div class="line">{</div>
<div class="line">  <a class="code hl_class" href="classLLMUnity_1_1RAG.html">RAG</a> rag;</div>
<div class="line"> </div>
<div class="line">  async <span class="keywordtype">void</span> Game(){</div>
<div class="line">    ...</div>
<div class="line">    <span class="keywordtype">string</span>[] inputs = <span class="keyword">new</span> <span class="keywordtype">string</span>[]{</div>
<div class="line">      <span class="stringliteral">&quot;Hi! I&#39;m a search system.&quot;</span>,</div>
<div class="line">      <span class="stringliteral">&quot;the weather is nice. I like it.&quot;</span>,</div>
<div class="line">      <span class="stringliteral">&quot;I&#39;m a RAG system&quot;</span></div>
<div class="line">    };</div>
<div class="line">    <span class="comment">// add the inputs to the RAG</span></div>
<div class="line">    <span class="keywordflow">foreach</span> (<span class="keywordtype">string</span> input <span class="keywordflow">in</span> inputs) await rag.<a class="code hl_function" href="classLLMUnity_1_1Searchable.html#a5b3409ff27d91f45a77f5bf1e3249161">Add</a>(input);</div>
<div class="line">    <span class="comment">// get the 2 most similar inputs and their distance (dissimilarity) to the search query</span></div>
<div class="line">    (<span class="keywordtype">string</span>[] results, <span class="keywordtype">float</span>[] distances) = await rag.<a class="code hl_function" href="classLLMUnity_1_1Searchable.html#a2bae1bf1901381972408c63f4ee7d9dc">Search</a>(<span class="stringliteral">&quot;hello!&quot;</span>, 2);</div>
<div class="line">    <span class="comment">// to get the most similar text parts (chunks), instead of full input, you can enable the returnChunks option</span></div>
<div class="line">    rag.<a class="code hl_function" href="classLLMUnity_1_1RAG.html#ac1082e5fb0cd8c98032ec02165c3ce26">ReturnChunks</a>(<span class="keyword">true</span>);</div>
<div class="line">    (results, distances) = await rag.<a class="code hl_function" href="classLLMUnity_1_1Searchable.html#a2bae1bf1901381972408c63f4ee7d9dc">Search</a>(<span class="stringliteral">&quot;hello!&quot;</span>, 2);</div>
<div class="line">    ...</div>
<div class="line">  }</div>
<div class="line">}</div>
<div class="ttc" id="aclassLLMUnity_1_1RAG_html_ac1082e5fb0cd8c98032ec02165c3ce26"><div class="ttname"><a href="classLLMUnity_1_1RAG.html#ac1082e5fb0cd8c98032ec02165c3ce26">LLMUnity.RAG.ReturnChunks</a></div><div class="ttdeci">void ReturnChunks(bool returnChunks)</div><div class="ttdoc">Set to true to return chunks or the direct input with the Search function.</div><div class="ttdef"><b>Definition</b> <a href="RAG_8cs_source.html#l00071">RAG.cs:71</a></div></div>
<div class="ttc" id="aclassLLMUnity_1_1Searchable_html_a2bae1bf1901381972408c63f4ee7d9dc"><div class="ttname"><a href="classLLMUnity_1_1Searchable.html#a2bae1bf1901381972408c63f4ee7d9dc">LLMUnity.Searchable.Search</a></div><div class="ttdeci">async Task&lt;(string[], float[])&gt; Search(string queryString, int k, string group=&quot;&quot;)</div><div class="ttdoc">Search for similar results to the provided query. The most similar results and their distances (dissi...</div><div class="ttdef"><b>Definition</b> <a href="Search_8cs_source.html#l00115">Search.cs:115</a></div></div>
<div class="ttc" id="aclassLLMUnity_1_1Searchable_html_a5b3409ff27d91f45a77f5bf1e3249161"><div class="ttname"><a href="classLLMUnity_1_1Searchable.html#a5b3409ff27d91f45a77f5bf1e3249161">LLMUnity.Searchable.Add</a></div><div class="ttdeci">Task&lt; int &gt; Add(string inputString, string group=&quot;&quot;)</div><div class="ttdoc">Adds a phrase to the search.</div></div>
</div><!-- fragment --><p>You can also add / search text inputs for groups of data e.g. for a specific character or scene: </p><div class="fragment"><div class="line">    <span class="comment">// add the inputs to the RAG for a group of data e.g. an orc character</span></div>
<div class="line">    <span class="keywordflow">foreach</span> (<span class="keywordtype">string</span> input <span class="keywordflow">in</span> inputs) await rag.<a class="code hl_function" href="classLLMUnity_1_1Searchable.html#a5b3409ff27d91f45a77f5bf1e3249161">Add</a>(input, <span class="stringliteral">&quot;orc&quot;</span>);</div>
<div class="line">    <span class="comment">// get the 2 most similar inputs for the group of data e.g. the orc character</span></div>
<div class="line">    (<span class="keywordtype">string</span>[] results, <span class="keywordtype">float</span>[] distances) = await rag.<a class="code hl_function" href="classLLMUnity_1_1Searchable.html#a2bae1bf1901381972408c63f4ee7d9dc">Search</a>(<span class="stringliteral">&quot;how do you feel?&quot;</span>, 2, <span class="stringliteral">&quot;orc&quot;</span>);</div>
<div class="line">...</div>
<div class="line"> </div>
<div class="line">You can save the <a class="code hl_class" href="classLLMUnity_1_1RAG.html">RAG</a> state (stored in the `Assets/StreamingAssets` folder):</div>
</div><!-- fragment --><p> {.cs} rag.Save("rag.zip"); </p><div class="fragment"><div class="line">and load it from disk:</div>
</div><!-- fragment --><p> {.cs} await rag.Load("rag.zip"); </p><div class="fragment"><div class="line">You can use the RAG to feed relevant data to the LLM based on a user message:</div>
</div><!-- fragment --><p> {.cs} string message = "How is the weather?"; (string[] similarPhrases, float[] distances) = await rag.Search(message, 3);</p>
<p>string prompt = "Answer the user query based on the provided data.

"; prompt += $"User query: {message}

"; prompt += $"Data:
"; foreach (string similarPhrase in similarPhrases) prompt += $"
- {similarPhrase}";</p>
<p>_ = llmAgent.Chat(prompt, HandleReply, ReplyCompleted); ```</p>
<p>The <code>RAG</code> sample includes an example RAG implementation as well as an example RAG-LLM integration.</p>
<p>That's all :sparkles:!</p>
<h1><a class="anchor" id="autotoc_md12"></a>
LLM model management</h1>
<p>LLM for Unity includes a built-in model manager for easy model handling.<br  />
 The model manager allows to load or download LLMs and can be found as part of the LLM GameObject:<br  />
 <img src="images/LLM_manager.png" alt="" width="360" class="inline"/></p>
<p>You can download models with the <code>Download model</code> button.<br  />
 LLM for Unity includes different state of the art models built-in for different model sizes, quantised with the Q4_K_M method.<br  />
 Alternative models can be downloaded from <a href="https://huggingface.co/models?library=gguf&amp;sort=downloads">HuggingFace</a> in .gguf format.<br  />
 You can download a model locally and load it with the <code>Load model</code> button, or copy the URL in the <code>Download model &gt; Custom URL</code> field to directly download it.<br  />
 If a HuggingFace model does not provide a gguf file, it can be converted to gguf with this <a href="https://huggingface.co/spaces/ggml-org/gguf-my-repo">online converter</a>.<br  />
</p>
<p><br  />
 <br  />
 Models added in the model manager are copied to the game during the building process.<br  />
 You can omit a model by deselecting the "Build" checkbox.<br  />
 To remove the model (but not delete it from disk) you can click the bin button.<br  />
 The path and URL of models can be diplayed in the expanded view of the model manager with the <code>&gt;&gt;</code> button:<br  />
 <img src="images/LLM_manager_expanded.png" alt="" width="600" class="inline"/></p>
<p>You can create lighter builds by selecting the <code>Download on Build</code> option.<br  />
 The models will be downloaded the first time the game starts instead of bundled in the build.<br  />
 If you have loaded a model locally you need to set its URL through the expanded view, otherwise it will be copied in the build.<br  />
</p>
<p>‚ùï Before using any model make sure you <b>check their license</b> ‚ùï</p>
<h1><a class="anchor" id="autotoc_md13"></a>
Examples</h1>
<p>The <a href="https://github.com/undreamai/LLMUnity/tree/main/Samples~">Samples~</a> folder contains several examples of interaction ü§ñ:</p><ul>
<li><a href="https://github.com/undreamai/LLMUnity/tree/main/Samples~/SimpleInteraction">SimpleInteraction</a>: Simple interaction with an AI character</li>
<li><a href="https://github.com/undreamai/LLMUnity/tree/main/Samples~/MultipleCharacters">MultipleCharacters</a>: Simple interaction using multiple AI characters</li>
<li><a href="https://github.com/undreamai/LLMUnity/tree/main/Samples~/FunctionCalling">FunctionCalling</a>: Function calling sample with structured output from the LLM</li>
<li><a href="https://github.com/undreamai/LLMUnity/tree/main/Samples~/RAG">RAG</a>: Semantic search using a Retrieval Augmented Generation (RAG) system. Includes example using a RAG to feed information to a LLM</li>
<li><a href="https://github.com/undreamai/LLMUnity/tree/main/Samples~/MobileDemo">MobileDemo</a>: Example mobile app for Android / iOS with an initial screen displaying the model download progress</li>
<li><a href="https://github.com/undreamai/LLMUnity/tree/main/Samples~/ChatBot">ChatBot</a>: Interaction between a player and a AI with a UI similar to a messaging app (see image below)</li>
<li><a href="https://github.com/undreamai/LLMUnity/tree/main/Samples~/KnowledgeBaseGame">KnowledgeBaseGame</a>: Simple detective game using a knowledge base to provide information to the LLM based on <a href="https://github.com/google/mysteryofthreebots">google/mysteryofthreebots</a></li>
</ul>
<p><img src="images/demo.gif" alt="" width="400" class="inline"/></p>
<p>To install a sample:</p><ul>
<li>Open the Package Manager: <code>Window &gt; Package Manager</code></li>
<li>Select the <code>LLM for Unity</code> Package. From the <code>Samples</code> Tab, click <code>Import</code> next to the sample you want to install.</li>
</ul>
<p>The samples can be run with the <code>Scene.unity</code> scene they contain inside their folder.<br  />
 In the scene, select the <code>LLM</code> GameObject and specify the LLM of your choice (see LLM model management).<br  />
 Save the scene, run and enjoy!</p>
<h1><a class="anchor" id="autotoc_md14"></a>
License</h1>
<p>The license of LLM for Unity is Apache 2.0 (<a class="el" href="md_LICENSE.html">LICENSE.md</a>) and uses third-party software with MIT and Apache licenses. Some models included in the asset define their own license terms, please review them before using each model. Third-party licenses can be found in the (<a class="el" href="md_Third_01Party_01Notices.html">Third Party Notices.md</a>). </p>
</div></div><!-- PageDoc -->
<a href="doxygen_crawl.html"/>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.10.0 </li>
  </ul>
</div>
</body>
</html>
