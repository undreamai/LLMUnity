<!-- HTML header for doxygen 1.9.1-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.10.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>LLM for Unity: Overview</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link rel="shortcut icon" href="logo_tiny.png" type="image/png">
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<!-- ... other metadata & script includes ... -->
<script type="text/javascript" src="doxygen-awesome-fragment-copy-button.js"></script>
<script type="text/javascript" src="doxygen-awesome-darkmode-toggle.js"></script>
<script type="text/javascript" src="doxygen-awesome-paragraph-link.js"></script>
<script type="text/javascript" src="doxygen-awesome-interactive-toc.js"></script>
<script type="text/javascript">
    DoxygenAwesomeFragmentCopyButton.init()
    DoxygenAwesomeDarkModeToggle.init()
    DoxygenAwesomeParagraphLink.init()
    DoxygenAwesomeInteractiveToc.init()
</script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="doxygen-awesome.css" rel="stylesheet" type="text/css"/>
<link href="custom.css" rel="stylesheet" type="text/css"/>
<link href="doxygen-awesome-sidebar-only.css" rel="stylesheet" type="text/css"/>
<link href="doxygen-awesome-sidebar-only-darkmode-toggle.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<!-- https://tholman.com/github-corners/ -->
<a href="https://github.com/undreamai/LLMUnity" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="logo_tiny.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">LLM for Unity
   &#160;<span id="projectnumber">v2.4.2</span>
   </div>
   <div id="projectbrief">Create characters in Unity with LLMs!</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.10.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){initNavTree('index.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">Overview </div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a class="anchor" id="md_README"></a></p>
<h1 align="center"><img src="images/logo.png" alt="" height="150" class="inline"/>  </h1>
<h3 align="center">Create characters in Unity with LLMs!</h3>
<p><a href="https://opensource.org/licenses/MIT"><img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="License: MIT" style="pointer-events: none;" class="inline"/></a> <a href="https://discord.gg/RwXKQb6zdv"><img src="https://discordapp.com/api/guilds/1194779009284841552/widget.png?style=shield" alt="" class="inline"/></a> <a href="https://www.reddit.com/user/UndreamAI"><img src="https://img.shields.io/badge/Reddit-%23FF4500.svg?style=flat&amp;logo=Reddit&amp;logoColor=white" alt="Reddit" style="pointer-events: none;" class="inline"/></a> <a href="https://www.linkedin.com/company/undreamai"><img src="https://img.shields.io/badge/LinkedIn-blue?style=flat&amp;logo=linkedin&amp;labelColor=blue" alt="LinkedIn" class="inline"/></a> <a href="https://assetstore.unity.com/packages/slug/273604"><img src="https://img.shields.io/badge/Asset%20Store-black.svg?style=flat&amp;logo=unity" alt="Asset Store" style="pointer-events: none;" class="inline"/></a> <a href="https://github.com/undreamai/LLMUnity"><img src="https://img.shields.io/github/stars/undreamai/LLMUnity?style=flat&amp;logo=github&amp;color=f5f5f5" alt="GitHub Repo stars" class="inline"/></a> <a href="https://undream.ai/LLMUnity"><img src="https://img.shields.io/badge/Docs-white.svg?logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwEAYAAAAHkiXEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABl0RVh0U29mdHdhcmUAd3d3Lmlua3NjYXBlLm9yZ5vuPBoAAATqSURBVHic7ZtbiE1RGMc349K4M5EwklwjzUhJCMmTJPJAYjQXJJcH8+Blkry4lPJA8aAoJbekDLmUS6E8SHJL5AW5JPf77eHv93C22Wfttc/ee+0zc/4vv+bMXvusvfZa3/q+b33H80oqqaSSSmqrKnPdgXjUvbvYq5f4+7f486eb/rRajRsn7t4tPngg/vol/vkj/vghXr0q7tghzpyZ//79+on79omXLombNondukXrd9GoSxdx8mSxqUm8eVNkgAvl0aPioEFip07i6dP52z15Ig4fbvVY2VVFhbhokXjrlogJiWvAg/jwoXjqVO73+leUny9eiFVV5mfMlLDRBw+KX76ISQ+0LZ8/F00v4uJFsWPHFh83O+rdWzx3TnQ9wCZ+/Sqyl5iux1RmTu3aiYcPi64H1pasALypoOv4/8SJXraEbXc9kLbECxo2TKyuFj9/zt9u+XIvG8LWv3wpuh5QW86f3/JznT+fv93s2S23C1Z72wbhtH692LdvMvdPSgzkhAkiJhT16ZO/PRPOmcr+Rda4aa5nclTeuZP7PDgRpr1g40bPrQYOFF0PYKHEC+raVVy8OFy7R49EArvURU4mrUAqaTY0iB8/2rXD+XCm5mbR9QAWylevorV7/VpkL0ld06eLpkiyWPj9u93179+LpFZwZ1PXtGnitWui64GMStPmG7SH1NSIJBNHjvTSFZvRvHlise0N9JcBtW1/44Y4dqx45IjnU0JxAGLpklPx+9VZFwPp/9v/eZDGjxcZh7dv4+mXtch+up7Rca+MsJvxiRNi6nvBhg25HWprZMaPGeOlqxEjxGKz+XGRTAAmyJnq6sR370TXA2NLW+8HNjZ62dLOnaLrAQ1r2zmqPH482n0mTfJCKmEvCJHUooNZE/369Elct06kqiKsONRfulTEFDsX8QDlIa5nup9374pE8IiZHPY+ly+LZE/37/cM6mC6IB6Vl4urV6fzfUG6d0/csyf37wsXRFInaM4ckTjGdPg+apTYs6dI3RIWwH//1DV1qkiuxNY2FzrTd+2y6y8z2HQU6efZs+KBAyJZ4v+V0h6ArlwROaQP0uPH4ooV4sqV8Xz/4MF211M2wwoOq1mzRAq5Pnywa5+4KDHE9mI7ly0TO3fOvZ6/eZCoKwB32HS0SMFV1DNtImBKHYstBROoQ4fEQk2RaS+qrxejmj5M7NatIhWARS82xUJfAKahzFcdPnq0GLYgy7Rnbd8e6rGKRyzpuNzPBQty709RcNSZf/KkuHCh2GpMDyKbGNcLYE+YMkVks336NFx7XhTZ3szXiBaqtWvFuAOxM2dEZiyH8UErgc8JLNun7E0aFffSI7RP6owZmz9kSO73HjsmXr8ukppYsybSYyQvBp5QfOjQ3M9tRR496pGgLf1JtLlzRZJzlFzGp4SWDnUxFCrdvy+uWiWa3DJe3N69oj8uSEq8CER88uaNOGBAOv2ILGY69TBBJoM8O0t72zaRoztXBzlLlrT8XARW/IQq82JTMv3mKmv0/9CC4mJMYPwrMSETxAyurRUxQVmXP1fEid7mzeK3b+n2Jzb16CFu2SIWmtNJiriVxANsyq0uoCJfTk4G9y4t24/bSQ0rTkP6gVTG3mz//uKMGSK/ucId5Xe9lZUi5eMMLGUgz56J5Hxu3xZ50Xg3RMIltVn9BRja26PYsBHgAAAAAElFTkSuQmCC" alt="Documentation" style="pointer-events: none;" class="inline"/></a></p>
<p>LLM for Unity enables seamless integration of Large Language Models (LLMs) within the Unity engine.<br  />
 It allows to create intelligent characters that your players can interact with for an immersive experience.<br  />
 The package also features a Retrieval-Augmented Generation (RAG) system that allows to performs semantic search across your data, which can be used to enhance the character's knowledge. LLM for Unity is built on top of the awesome <a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a> library.</p>
<h1><a class="anchor" id="autotoc_md1"></a>
At a glance</h1>
<ul>
<li>💻 Cross-platform! Windows, Linux, macOS, iOS and Android</li>
<li>🏠 Runs locally without internet access. No data ever leave the game!</li>
<li>⚡ Blazing fast inference on CPU and GPU (Nvidia, AMD, Apple Metal)</li>
<li>🤗 Supports all major LLM models</li>
<li>🔧 Easy to setup, call with a single line of code</li>
<li>💰 Free to use for both personal and commercial purposes</li>
</ul>
<p>🧪 Tested on Unity: 2021 LTS, 2022 LTS, 2023, Unity 6<br  />
 🚦 <a href="https://github.com/orgs/undreamai/projects/2/views/10">Upcoming Releases</a></p>
<h1><a class="anchor" id="autotoc_md2"></a>
How to help</h1>
<ul>
<li><a href="https://github.com/undreamai/LLMUnity">⭐ Star</a> the repo, leave us a <a href="https://assetstore.unity.com/packages/slug/273604">review</a> and spread the word about the project!</li>
<li>Join us at <a href="https://discord.gg/RwXKQb6zdv">Discord</a> and say hi.</li>
<li>Contribute by submitting feature requests, bugs or even your own PR.</li>
<li><a href="https://github.com/sponsors/amakropoulos"><img src="https://img.shields.io/static/v1?label=Sponsor&amp;message=%E2%9D%A4&amp;logo=GitHub&amp;color=%23fe8e86" alt="" class="inline"/></a> this work to allow even cooler features!</li>
</ul>
<h1><a class="anchor" id="autotoc_md3"></a>
Games / Projects using LLM for Unity</h1>
<ul>
<li><a href="https://store.steampowered.com/app/2778780/Verbal_Verdict/">Verbal Verdict</a></li>
<li><a href="https://store.epicgames.com/de/p/i-chatbot-aisylum-83b2b5">I, Chatbot: AISYLUM</a></li>
<li><a href="https://unicorninteractive.itch.io/nameless-souls-of-the-void">Nameless Souls of the Void</a></li>
<li><a href="https://roadedlich.itch.io/murder-in-aisle-4">Murder in Aisle 4</a></li>
<li><a href="https://helixngc7293.itch.io/finicky-food-delivery-ai">Finicky Food Delivery AI</a></li>
<li><a href="https://whynames.itch.io/aiemotionalgirlfriend">AI Emotional Girlfriend</a></li>
<li><a href="https://store.steampowered.com/app/2532160/Case_Closed">Case Closed</a></li>
<li><a href="https://github.com/IhateCreatingUserNames2/MaiMai">MaiMai AI Agent System</a></li>
</ul>
<p>Contact us to add your project!</p>
<h1><a class="anchor" id="autotoc_md4"></a>
Setup</h1>
<p><em>Method 1: Install using the asset store</em></p><ul>
<li>Open the <a href="https://assetstore.unity.com/packages/slug/273604">LLM for Unity</a> asset page and click <code>Add to My Assets</code></li>
<li>Open the Package Manager in Unity: <code>Window &gt; Package Manager</code></li>
<li>Select the <code>Packages: My Assets</code> option from the drop-down</li>
<li>Select the <code>LLM for Unity</code> package, click <code>Download</code> and then <code>Import</code></li>
</ul>
<p><em>Method 2: Install using the GitHub repo:</em></p><ul>
<li>Open the Package Manager in Unity: <code>Window &gt; Package Manager</code></li>
<li>Click the <code>+</code> button and select <code>Add package from git URL</code></li>
<li>Use the repository URL <code><a href="https://github.com/undreamai/LLMUnity.git">https://github.com/undreamai/LLMUnity.git</a></code> and click <code>Add</code></li>
</ul>
<h1><a class="anchor" id="autotoc_md5"></a>
How to use</h1>
<p><img src="images/character.png" alt="" height="300" class="inline"/></p>
<p>First you will setup the LLM for your game 🏎:</p><ul>
<li>Create an empty GameObject.<br  />
In the GameObject Inspector click <code>Add Component</code> and select the LLM script.</li>
<li>Download one of the default models with the <code>Download Model</code> button (~GBs).<br  />
Or load your own .gguf model with the <code>Load model</code> button (see LLM model management).</li>
</ul>
<p>Then you can setup each of your characters as follows 🙋‍♀️:</p><ul>
<li>Create an empty GameObject for the character.<br  />
In the GameObject Inspector click <code>Add Component</code> and select the LLMCharacter script.</li>
<li>Define the role of your AI in the <code>Prompt</code>. You can define the name of the AI (<code>AI Name</code>) and the player (<code>Player Name</code>).</li>
<li>(Optional) Select the LLM constructed above in the <code>LLM</code> field if you have more than one LLM GameObjects.</li>
</ul>
<p>You can also adjust the LLM and character settings according to your preference (see Options).</p>
<p>In your script you can then use it as follows 🦄: </p><div class="fragment"><div class="line"><span class="keyword">using </span><a class="code hl_namespace" href="namespaceLLMUnity.html">LLMUnity</a>;</div>
<div class="line"> </div>
<div class="line"><span class="keyword">public</span> <span class="keyword">class </span>MyScript {</div>
<div class="line">  <span class="keyword">public</span> <a class="code hl_class" href="classLLMUnity_1_1LLMCharacter.html">LLMCharacter</a> llmCharacter;</div>
<div class="line">  </div>
<div class="line">  <span class="keywordtype">void</span> HandleReply(<span class="keywordtype">string</span> reply){</div>
<div class="line">    <span class="comment">// do something with the reply from the model</span></div>
<div class="line">    Debug.Log(reply);</div>
<div class="line">  }</div>
<div class="line">  </div>
<div class="line">  <span class="keywordtype">void</span> Game(){</div>
<div class="line">    <span class="comment">// your game function</span></div>
<div class="line">    ...</div>
<div class="line">    <span class="keywordtype">string</span> message = <span class="stringliteral">&quot;Hello bot!&quot;</span>;</div>
<div class="line">    _ = llmCharacter.<a class="code hl_function" href="classLLMUnity_1_1LLMCharacter.html#a1367eb182ec0efe9322a3102ea22952e">Chat</a>(message, HandleReply);</div>
<div class="line">    ...</div>
<div class="line">  }</div>
<div class="line">}</div>
<div class="ttc" id="aclassLLMUnity_1_1LLMCharacter_html"><div class="ttname"><a href="classLLMUnity_1_1LLMCharacter.html">LLMUnity.LLMCharacter</a></div><div class="ttdoc">Class implementing the LLM characters.</div><div class="ttdef"><b>Definition</b> <a href="LLMCharacter_8cs_source.html#l00018">LLMCharacter.cs:19</a></div></div>
<div class="ttc" id="aclassLLMUnity_1_1LLMCharacter_html_a1367eb182ec0efe9322a3102ea22952e"><div class="ttname"><a href="classLLMUnity_1_1LLMCharacter.html#a1367eb182ec0efe9322a3102ea22952e">LLMUnity.LLMCharacter.Chat</a></div><div class="ttdeci">virtual async Task&lt; string &gt; Chat(string query, Callback&lt; string &gt; callback=null, EmptyCallback completionCallback=null, bool addToHistory=true)</div><div class="ttdoc">Chat functionality of the LLM. It calls the LLM completion based on the provided query including the ...</div><div class="ttdef"><b>Definition</b> <a href="LLMCharacter_8cs_source.html#l00464">LLMCharacter.cs:464</a></div></div>
<div class="ttc" id="anamespaceLLMUnity_html"><div class="ttname"><a href="namespaceLLMUnity.html">LLMUnity</a></div><div class="ttdef"><b>Definition</b> <a href="LLM_8cs_source.html#l00011">LLM.cs:12</a></div></div>
</div><!-- fragment --><p> You can also specify a function to call when the model reply has been completed.<br  />
 This is useful if the <code>Stream</code> option is enabled for continuous output from the model (default behaviour): </p><div class="fragment"><div class="line"><span class="keywordtype">void</span> ReplyCompleted(){</div>
<div class="line">  <span class="comment">// do something when the reply from the model is complete</span></div>
<div class="line">  Debug.Log(<span class="stringliteral">&quot;The AI replied&quot;</span>);</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line"><span class="keywordtype">void</span> Game(){</div>
<div class="line">  <span class="comment">// your game function</span></div>
<div class="line">  ...</div>
<div class="line">  <span class="keywordtype">string</span> message = <span class="stringliteral">&quot;Hello bot!&quot;</span>;</div>
<div class="line">  _ = llmCharacter.<a class="code hl_function" href="classLLMUnity_1_1LLMCharacter.html#a1367eb182ec0efe9322a3102ea22952e">Chat</a>(message, HandleReply, ReplyCompleted);</div>
<div class="line">  ...</div>
<div class="line">}</div>
</div><!-- fragment --><p>To stop the chat without waiting for its completion you can use: </p><div class="fragment"><div class="line">llmCharacter.<a class="code hl_function" href="classLLMUnity_1_1LLMCaller.html#a5914034b6b799e018380152c0136b511">CancelRequests</a>();</div>
<div class="ttc" id="aclassLLMUnity_1_1LLMCaller_html_a5914034b6b799e018380152c0136b511"><div class="ttname"><a href="classLLMUnity_1_1LLMCaller.html#a5914034b6b799e018380152c0136b511">LLMUnity.LLMCaller.CancelRequests</a></div><div class="ttdeci">virtual void CancelRequests()</div><div class="ttdoc">Cancel the ongoing requests e.g. Chat, Complete.</div><div class="ttdef"><b>Definition</b> <a href="LLMCaller_8cs_source.html#l00230">LLMCaller.cs:230</a></div></div>
</div><!-- fragment --><ul>
<li>Finally, in the Inspector of the GameObject of your script, select the LLMCharacter GameObject created above as the llmCharacter property.</li>
</ul>
<p>That's all ✨! <br  />
<br  />
 You can also:</p>
<details >
<summary >
Build a mobile app</summary>
<p></p>
<p><b>iOS</b> iOS can be built with the default player settings.</p>
<p><b>Android</b> On Android you need to specify the <code>IL2CPP</code> scripting backend and the <code>ARM64</code> as the target architecture in the player settings.<br  />
 These settings can be accessed from the <code>Edit &gt; Project Settings</code> menu within the <code>Player &gt; Other Settings</code> section.<br  />
 <img src="images/android.png" alt="" width="400" class="inline"/></p>
<p>Since mobile app sizes are typically small, you can download the LLM models the first time the app launches. This functionality can be enabled with the <code>Download on Build</code> option. In your project you can wait until the model download is complete with: </p><div class="fragment"><div class="line">await <a class="code hl_class" href="classLLMUnity_1_1LLM.html">LLM</a>.<a class="code hl_function" href="classLLMUnity_1_1LLM.html#a1f41b07eb274fd6194f0e97eea4ca331">WaitUntilModelSetup</a>();</div>
<div class="ttc" id="aclassLLMUnity_1_1LLM_html"><div class="ttname"><a href="classLLMUnity_1_1LLM.html">LLMUnity.LLM</a></div><div class="ttdoc">Class implementing the LLM server.</div><div class="ttdef"><b>Definition</b> <a href="LLM_8cs_source.html#l00018">LLM.cs:19</a></div></div>
<div class="ttc" id="aclassLLMUnity_1_1LLM_html_a1f41b07eb274fd6194f0e97eea4ca331"><div class="ttname"><a href="classLLMUnity_1_1LLM.html#a1f41b07eb274fd6194f0e97eea4ca331">LLMUnity.LLM.WaitUntilModelSetup</a></div><div class="ttdeci">static async Task&lt; bool &gt; WaitUntilModelSetup(Callback&lt; float &gt; downloadProgressCallback=null)</div><div class="ttdoc">Allows to wait until the LLM models are downloaded and ready.</div><div class="ttdef"><b>Definition</b> <a href="LLM_8cs_source.html#l00161">LLM.cs:161</a></div></div>
</div><!-- fragment --><p> You can also receive calls during the download with the download progress: </p><div class="fragment"><div class="line">await <a class="code hl_class" href="classLLMUnity_1_1LLM.html">LLM</a>.<a class="code hl_function" href="classLLMUnity_1_1LLM.html#a1f41b07eb274fd6194f0e97eea4ca331">WaitUntilModelSetup</a>(SetProgress);</div>
<div class="line"> </div>
<div class="line"><span class="keywordtype">void</span> SetProgress(<span class="keywordtype">float</span> progress){</div>
<div class="line">  <span class="keywordtype">string</span> progressPercent = ((int)(progress * 100)).ToString() + <span class="stringliteral">&quot;%&quot;</span>;</div>
<div class="line">  Debug.Log($<span class="stringliteral">&quot;Download progress: {progressPercent}&quot;</span>);</div>
<div class="line">}</div>
</div><!-- fragment --><p> This is useful to present a progress bar or something similar. The <a href="https://github.com/undreamai/LLMUnity/tree/main/Samples~/MobileDemo">MobileDemo</a> is an example application for Android / iOS.</p>
<p></p>
</details>
<details >
<summary >
Restrict the output of the LLM / Function calling</summary>
<p></p>
<p>To restrict the output of the LLM you can use a GBNF grammar, read more <a href="https://github.com/ggerganov/llama.cpp/tree/master/grammars">here</a>.<br  />
 The grammar can be saved in a .gbnf file and loaded at the LLMCharacter with the <code>Load Grammar</code> button (Advanced options).<br  />
 For instance to receive replies in json format you can use the <a href="https://github.com/ggerganov/llama.cpp/blob/b4218/grammars/json.gbnf">json.gbnf</a> grammar.<br  />
</p>
<p>Alternatively you can set the grammar directly with code: </p><div class="fragment"><div class="line">llmCharacter.grammarString = <span class="stringliteral">&quot;your grammar here&quot;</span>;</div>
</div><!-- fragment --><p>For function calling you can define similarly a grammar that allows only the function names as output, and then call the respective function.<br  />
 You can look into the <a href="https://github.com/undreamai/LLMUnity/tree/main/Samples~/FunctionCalling">FunctionCalling</a> sample for an example implementation.</p>
<p></p>
</details>
<details >
<summary >
Access / Save / Load your chat history</summary>
<p>The chat history of a <code>LLMCharacter</code> is retained in the <code>chat</code> variable that is a list of <code>ChatMessage</code> objects.<br  />
 The ChatMessage is a struct that defines the <code>role</code> of the message and the <code>content</code>.<br  />
 The first element of the list is always the system prompt and then alternating messages with the player prompt and the AI reply.<br  />
 You can modify the chat history directly in this list.<br  />
</p>
<p>To automatically save / load your chat history, you can specify the <code>Save</code> parameter of the LLMCharacter to the filename (or relative path) of your choice. The file is saved in the <a href="https://docs.unity3d.com/ScriptReference/Application-persistentDataPath.html">persistentDataPath folder of Unity</a>. This also saves the state of the LLM which means that the previously cached prompt does not need to be recomputed.</p>
<p>To manually save your chat history, you can use: </p><div class="fragment"><div class="line">llmCharacter.<a class="code hl_function" href="classLLMUnity_1_1LLMCharacter.html#a8777cf02ab4ecf5a967ade7e93925108">Save</a>(<span class="stringliteral">&quot;filename&quot;</span>);</div>
<div class="ttc" id="aclassLLMUnity_1_1LLMCharacter_html_a8777cf02ab4ecf5a967ade7e93925108"><div class="ttname"><a href="classLLMUnity_1_1LLMCharacter.html#a8777cf02ab4ecf5a967ade7e93925108">LLMUnity.LLMCharacter.Save</a></div><div class="ttdeci">virtual async Task&lt; string &gt; Save(string filename)</div><div class="ttdoc">Saves the chat history and cache to the provided filename / relative path.</div><div class="ttdef"><b>Definition</b> <a href="LLMCharacter_8cs_source.html#l00590">LLMCharacter.cs:590</a></div></div>
</div><!-- fragment --><p> and to load the history: </p><div class="fragment"><div class="line">llmCharacter.<a class="code hl_function" href="classLLMUnity_1_1LLMCharacter.html#a5fcf385a45c9cd71e2428b7442a163a3">Load</a>(<span class="stringliteral">&quot;filename&quot;</span>);</div>
<div class="ttc" id="aclassLLMUnity_1_1LLMCharacter_html_a5fcf385a45c9cd71e2428b7442a163a3"><div class="ttname"><a href="classLLMUnity_1_1LLMCharacter.html#a5fcf385a45c9cd71e2428b7442a163a3">LLMUnity.LLMCharacter.Load</a></div><div class="ttdeci">virtual async Task&lt; string &gt; Load(string filename)</div><div class="ttdoc">Load the chat history and cache from the provided filename / relative path.</div><div class="ttdef"><b>Definition</b> <a href="LLMCharacter_8cs_source.html#l00609">LLMCharacter.cs:609</a></div></div>
</div><!-- fragment --><p> where filename the filename or relative path of your choice.</p>
<p></p>
</details>
<details >
<summary >
Process the prompt at the beginning of your app for faster initial processing time</summary>
<p></p>
<div class="fragment"><div class="line"><span class="keywordtype">void</span> WarmupCompleted(){</div>
<div class="line">  <span class="comment">// do something when the warmup is complete</span></div>
<div class="line">  Debug.Log(<span class="stringliteral">&quot;The AI is nice and ready&quot;</span>);</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line"><span class="keywordtype">void</span> Game(){</div>
<div class="line">  <span class="comment">// your game function</span></div>
<div class="line">  ...</div>
<div class="line">  _ = llmCharacter.<a class="code hl_function" href="classLLMUnity_1_1LLMCharacter.html#aa582248b495a4aa8dac46803e2412bb4">Warmup</a>(WarmupCompleted);</div>
<div class="line">  ...</div>
<div class="line">}</div>
<div class="ttc" id="aclassLLMUnity_1_1LLMCharacter_html_aa582248b495a4aa8dac46803e2412bb4"><div class="ttname"><a href="classLLMUnity_1_1LLMCharacter.html#aa582248b495a4aa8dac46803e2412bb4">LLMUnity.LLMCharacter.Warmup</a></div><div class="ttdeci">virtual async Task Warmup(EmptyCallback completionCallback=null)</div><div class="ttdoc">Allow to warm-up a model by processing the system prompt. The prompt processing will be cached (if ca...</div><div class="ttdef"><b>Definition</b> <a href="LLMCharacter_8cs_source.html#l00524">LLMCharacter.cs:524</a></div></div>
</div><!-- fragment --><p></p>
</details>
<details >
<summary >
Decide whether or not to add the message to the chat/prompt history</summary>
<p></p>
<p>The last argument of the <code>Chat</code> function is a boolean that specifies whether to add the message to the history (default: true): </p><div class="fragment"><div class="line"><span class="keywordtype">void</span> Game(){</div>
<div class="line">  <span class="comment">// your game function</span></div>
<div class="line">  ...</div>
<div class="line">  <span class="keywordtype">string</span> message = <span class="stringliteral">&quot;Hello bot!&quot;</span>;</div>
<div class="line">  _ = llmCharacter.<a class="code hl_function" href="classLLMUnity_1_1LLMCharacter.html#a1367eb182ec0efe9322a3102ea22952e">Chat</a>(message, HandleReply, ReplyCompleted, <span class="keyword">false</span>);</div>
<div class="line">  ...</div>
<div class="line">}</div>
</div><!-- fragment --><p></p>
</details>
<details >
<summary >
Use pure text completion</summary>
<p></p>
<div class="fragment"><div class="line"><span class="keywordtype">void</span> Game(){</div>
<div class="line">  <span class="comment">// your game function</span></div>
<div class="line">  ...</div>
<div class="line">  <span class="keywordtype">string</span> message = <span class="stringliteral">&quot;The cat is away&quot;</span>;</div>
<div class="line">  _ = llmCharacter.<a class="code hl_function" href="classLLMUnity_1_1LLMCharacter.html#adf9cc5ead56e07d72f7cf9a79acd4128">Complete</a>(message, HandleReply, ReplyCompleted);</div>
<div class="line">  ...</div>
<div class="line">}</div>
<div class="ttc" id="aclassLLMUnity_1_1LLMCharacter_html_adf9cc5ead56e07d72f7cf9a79acd4128"><div class="ttname"><a href="classLLMUnity_1_1LLMCharacter.html#adf9cc5ead56e07d72f7cf9a79acd4128">LLMUnity.LLMCharacter.Complete</a></div><div class="ttdeci">virtual async Task&lt; string &gt; Complete(string prompt, Callback&lt; string &gt; callback=null, EmptyCallback completionCallback=null)</div><div class="ttdoc">Pure completion functionality of the LLM. It calls the LLM completion based solely on the provided pr...</div><div class="ttdef"><b>Definition</b> <a href="LLMCharacter_8cs_source.html#l00504">LLMCharacter.cs:504</a></div></div>
</div><!-- fragment --><p></p>
</details>
<details >
<summary >
Wait for the reply before proceeding to the next lines of code</summary>
<p></p>
<p>For this you can use the <code>async</code>/<code>await</code> functionality: </p><div class="fragment"><div class="line">async <span class="keywordtype">void</span> Game(){</div>
<div class="line">  <span class="comment">// your game function</span></div>
<div class="line">  ...</div>
<div class="line">  <span class="keywordtype">string</span> message = <span class="stringliteral">&quot;Hello bot!&quot;</span>;</div>
<div class="line">  <span class="keywordtype">string</span> reply = await llmCharacter.<a class="code hl_function" href="classLLMUnity_1_1LLMCharacter.html#a1367eb182ec0efe9322a3102ea22952e">Chat</a>(message, HandleReply, ReplyCompleted);</div>
<div class="line">  Debug.Log(reply);</div>
<div class="line">  ...</div>
<div class="line">}</div>
</div><!-- fragment --><p></p>
</details>
<details >
<summary >
Add a LLM / LLMCharacter component programmatically</summary>
<p></p>
<div class="fragment"><div class="line"><span class="keyword">using </span>UnityEngine;</div>
<div class="line"><span class="keyword">using </span><a class="code hl_namespace" href="namespaceLLMUnity.html">LLMUnity</a>;</div>
<div class="line"> </div>
<div class="line"><span class="keyword">public</span> <span class="keyword">class </span>MyScript : MonoBehaviour</div>
<div class="line">{</div>
<div class="line">    <a class="code hl_class" href="classLLMUnity_1_1LLM.html">LLM</a> llm;</div>
<div class="line">    <a class="code hl_class" href="classLLMUnity_1_1LLMCharacter.html">LLMCharacter</a> llmCharacter;</div>
<div class="line"> </div>
<div class="line">    async <span class="keywordtype">void</span> Start()</div>
<div class="line">    {</div>
<div class="line">        <span class="comment">// disable gameObject so that theAwake is not called immediately</span></div>
<div class="line">        gameObject.SetActive(<span class="keyword">false</span>);</div>
<div class="line"> </div>
<div class="line">        <span class="comment">// Add an LLM object</span></div>
<div class="line">        llm = gameObject.AddComponent&lt;<a class="code hl_class" href="classLLMUnity_1_1LLM.html">LLM</a>&gt;();</div>
<div class="line">        <span class="comment">// set the model using the filename of the model.</span></div>
<div class="line">        <span class="comment">// The model needs to be added to the LLM model manager (see LLM model management) by loading or downloading it.</span></div>
<div class="line">        <span class="comment">// Otherwise the model file can be copied directly inside the StreamingAssets folder.</span></div>
<div class="line">        llm.<a class="code hl_function" href="classLLMUnity_1_1LLM.html#a9cdc4850537724d94bf88e7b78372883">SetModel</a>(<span class="stringliteral">&quot;Phi-3-mini-4k-instruct-q4.gguf&quot;</span>);</div>
<div class="line">        <span class="comment">// optional: you can also set loras in a similar fashion and set their weights (if needed)</span></div>
<div class="line">        llm.<a class="code hl_function" href="classLLMUnity_1_1LLM.html#a5c4cd1f8b959b1f36c8c50d08ee114c4">AddLora</a>(<span class="stringliteral">&quot;my-lora.gguf&quot;</span>);</div>
<div class="line">        llm.<a class="code hl_function" href="classLLMUnity_1_1LLM.html#a26e01ce3a14c30da752cf216acfbb3ff">SetLoraWeight</a>(0.5f);</div>
<div class="line">        <span class="comment">// optional: you can set the chat template of the model if it is not correctly identified</span></div>
<div class="line">        <span class="comment">// You can find a list of chat templates in the ChatTemplate.templates.Keys</span></div>
<div class="line">        llm.<a class="code hl_function" href="classLLMUnity_1_1LLM.html#ad4c7250286a33527cb211bd980f1c307">SetTemplate</a>(<span class="stringliteral">&quot;phi-3&quot;</span>);</div>
<div class="line">        <span class="comment">// optional: set number of threads</span></div>
<div class="line">        llm.numThreads = -1;</div>
<div class="line">        <span class="comment">// optional: enable GPU by setting the number of model layers to offload to it</span></div>
<div class="line">        llm.numGPULayers = 10;</div>
<div class="line"> </div>
<div class="line">        <span class="comment">// Add an LLMCharacter object</span></div>
<div class="line">        llmCharacter = gameObject.AddComponent&lt;<a class="code hl_class" href="classLLMUnity_1_1LLMCharacter.html">LLMCharacter</a>&gt;();</div>
<div class="line">        <span class="comment">// set the LLM object that handles the model</span></div>
<div class="line">        llmCharacter.llm = llm;</div>
<div class="line">        <span class="comment">// set the character prompt</span></div>
<div class="line">        llmCharacter.<a class="code hl_function" href="classLLMUnity_1_1LLMCharacter.html#affc13b3416002473688130217f1b42df">SetPrompt</a>(<span class="stringliteral">&quot;A chat between a curious human and an artificial intelligence assistant.&quot;</span>);</div>
<div class="line">        <span class="comment">// set the AI and player name</span></div>
<div class="line">        llmCharacter.AIName = <span class="stringliteral">&quot;AI&quot;</span>;</div>
<div class="line">        llmCharacter.playerName = <span class="stringliteral">&quot;Human&quot;</span>;</div>
<div class="line">        <span class="comment">// optional: set streaming to false to get the complete result in one go</span></div>
<div class="line">        <span class="comment">// llmCharacter.stream = true;</span></div>
<div class="line">        <span class="comment">// optional: set a save path</span></div>
<div class="line">        <span class="comment">// llmCharacter.save = &quot;AICharacter1&quot;;</span></div>
<div class="line">        <span class="comment">// optional: enable the save cache to avoid recomputation when loading a save file (requires ~100 MB)</span></div>
<div class="line">        <span class="comment">// llmCharacter.saveCache = true;</span></div>
<div class="line">        <span class="comment">// optional: set a grammar</span></div>
<div class="line">        <span class="comment">// await llmCharacter.SetGrammar(&quot;json.gbnf&quot;);</span></div>
<div class="line"> </div>
<div class="line">        <span class="comment">// re-enable gameObject</span></div>
<div class="line">        gameObject.SetActive(<span class="keyword">true</span>);</div>
<div class="line">    }</div>
<div class="line">}</div>
<div class="ttc" id="aclassLLMUnity_1_1LLMCharacter_html_affc13b3416002473688130217f1b42df"><div class="ttname"><a href="classLLMUnity_1_1LLMCharacter.html#affc13b3416002473688130217f1b42df">LLMUnity.LLMCharacter.SetPrompt</a></div><div class="ttdeci">virtual void SetPrompt(string newPrompt, bool clearChat=true)</div><div class="ttdoc">Set the system prompt for the LLMCharacter.</div><div class="ttdef"><b>Definition</b> <a href="LLMCharacter_8cs_source.html#l00239">LLMCharacter.cs:239</a></div></div>
<div class="ttc" id="aclassLLMUnity_1_1LLM_html_a26e01ce3a14c30da752cf216acfbb3ff"><div class="ttname"><a href="classLLMUnity_1_1LLM.html#a26e01ce3a14c30da752cf216acfbb3ff">LLMUnity.LLM.SetLoraWeight</a></div><div class="ttdeci">void SetLoraWeight(string path, float weight)</div><div class="ttdoc">Allows to change the weight (scale) of a LORA model in the LLM.</div><div class="ttdef"><b>Definition</b> <a href="LLM_8cs_source.html#l00306">LLM.cs:306</a></div></div>
<div class="ttc" id="aclassLLMUnity_1_1LLM_html_a5c4cd1f8b959b1f36c8c50d08ee114c4"><div class="ttname"><a href="classLLMUnity_1_1LLM.html#a5c4cd1f8b959b1f36c8c50d08ee114c4">LLMUnity.LLM.AddLora</a></div><div class="ttdeci">void AddLora(string path, float weight=1)</div><div class="ttdoc">Allows to add a LORA model to use in the LLM. The model provided is copied to the Assets/StreamingAss...</div><div class="ttdef"><b>Definition</b> <a href="LLM_8cs_source.html#l00272">LLM.cs:272</a></div></div>
<div class="ttc" id="aclassLLMUnity_1_1LLM_html_a9cdc4850537724d94bf88e7b78372883"><div class="ttname"><a href="classLLMUnity_1_1LLM.html#a9cdc4850537724d94bf88e7b78372883">LLMUnity.LLM.SetModel</a></div><div class="ttdeci">void SetModel(string path)</div><div class="ttdoc">Allows to set the model used by the LLM. The model provided is copied to the Assets/StreamingAssets f...</div><div class="ttdef"><b>Definition</b> <a href="LLM_8cs_source.html#l00231">LLM.cs:231</a></div></div>
<div class="ttc" id="aclassLLMUnity_1_1LLM_html_ad4c7250286a33527cb211bd980f1c307"><div class="ttname"><a href="classLLMUnity_1_1LLM.html#ad4c7250286a33527cb211bd980f1c307">LLMUnity.LLM.SetTemplate</a></div><div class="ttdeci">void SetTemplate(string templateName, bool setDirty=true)</div><div class="ttdoc">Set the chat template for the LLM.</div><div class="ttdef"><b>Definition</b> <a href="LLM_8cs_source.html#l00337">LLM.cs:337</a></div></div>
</div><!-- fragment --><p></p>
</details>
<details >
<summary >
Use a remote server</summary>
<p></p>
<p>You can use a remote server to carry out the processing and implement characters that interact with it.</p>
<p><b>Create the server</b><br  />
 To create the server:</p><ul>
<li>Create a project with a GameObject using the <code>LLM</code> script as described above</li>
<li>Enable the <code>Remote</code> option of the <code>LLM</code> and optionally configure the server parameters: port, API key, SSL certificate, SSL key</li>
<li>Build and run to start the server</li>
</ul>
<p>Alternatively you can use a server binary for easier deployment:</p><ul>
<li>Run the above scene from the Editor and copy the command from the Debug messages (starting with "Server command:")</li>
<li>Download the <a href="https://github.com/undreamai/LlamaLib/releases/download/v1.2.1/undreamai-v1.2.1-server.zip">server binaries</a> and <a href="https://github.com/undreamai/LlamaLib/releases/download/v1.2.1/undreamai-v1.2.1-llamacpp-full.zip">DLLs</a> and extract them into the same folder</li>
<li>Find the architecture you are interested in from the folder above e.g. for Windows and CUDA use the <code>windows-cuda-cu12.2.0</code>.<br  />
You can also check the architecture that works for your system from the Debug messages (starting with "Using architecture").</li>
<li>From command line change directory to the architecture folder selected and start the server by running the command copied from above.</li>
</ul>
<p>In both cases you'll need to enable 'Allow Downloads Over HTTP' in the project settings.</p>
<p><b>Create the characters</b><br  />
 Create a second project with the game characters using the <code>LLMCharacter</code> script as described above. Enable the <code>Remote</code> option and configure the host with the IP address (starting with "http://") and port of the server.</p>
<p></p>
</details>
<details >
<summary >
Compute embeddings using a LLM</summary>
<p></p>
<p>The <code>Embeddings</code> function can be used to obtain the emdeddings of a phrase: </p><div class="fragment"><div class="line">List&lt;float&gt; embeddings = await llmCharacter.<a class="code hl_function" href="classLLMUnity_1_1LLMCaller.html#a2344c568eafd2918a33fe418841d5481">Embeddings</a>(<span class="stringliteral">&quot;hi, how are you?&quot;</span>);</div>
<div class="ttc" id="aclassLLMUnity_1_1LLMCaller_html_a2344c568eafd2918a33fe418841d5481"><div class="ttname"><a href="classLLMUnity_1_1LLMCaller.html#a2344c568eafd2918a33fe418841d5481">LLMUnity.LLMCaller.Embeddings</a></div><div class="ttdeci">virtual async Task&lt; List&lt; float &gt; &gt; Embeddings(string query, Callback&lt; List&lt; float &gt; &gt; callback=null)</div><div class="ttdoc">Computes the embeddings of the provided input.</div><div class="ttdef"><b>Definition</b> <a href="LLMCaller_8cs_source.html#l00378">LLMCaller.cs:378</a></div></div>
</div><!-- fragment --><p></p>
</details>
<p>A <b>detailed documentation</b> on function level can be found here: <a href="https://undream.ai/LLMUnity"><img src="https://img.shields.io/badge/Documentation-white.svg?logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwEAYAAAAHkiXEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABl0RVh0U29mdHdhcmUAd3d3Lmlua3NjYXBlLm9yZ5vuPBoAAATqSURBVHic7ZtbiE1RGMc349K4M5EwklwjzUhJCMmTJPJAYjQXJJcH8+Blkry4lPJA8aAoJbekDLmUS6E8SHJL5AW5JPf77eHv93C22Wfttc/ee+0zc/4vv+bMXvusvfZa3/q+b33H80oqqaSSSmqrKnPdgXjUvbvYq5f4+7f486eb/rRajRsn7t4tPngg/vol/vkj/vghXr0q7tghzpyZ//79+on79omXLombNondukXrd9GoSxdx8mSxqUm8eVNkgAvl0aPioEFip07i6dP52z15Ig4fbvVY2VVFhbhokXjrlogJiWvAg/jwoXjqVO73+leUny9eiFVV5mfMlLDRBw+KX76ISQ+0LZ8/F00v4uJFsWPHFh83O+rdWzx3TnQ9wCZ+/Sqyl5iux1RmTu3aiYcPi64H1pasALypoOv4/8SJXraEbXc9kLbECxo2TKyuFj9/zt9u+XIvG8LWv3wpuh5QW86f3/JznT+fv93s2S23C1Z72wbhtH692LdvMvdPSgzkhAkiJhT16ZO/PRPOmcr+Rda4aa5nclTeuZP7PDgRpr1g40bPrQYOFF0PYKHEC+raVVy8OFy7R49EArvURU4mrUAqaTY0iB8/2rXD+XCm5mbR9QAWylevorV7/VpkL0ld06eLpkiyWPj9u93179+LpFZwZ1PXtGnitWui64GMStPmG7SH1NSIJBNHjvTSFZvRvHlise0N9JcBtW1/44Y4dqx45IjnU0JxAGLpklPx+9VZFwPp/9v/eZDGjxcZh7dv4+mXtch+up7Rca+MsJvxiRNi6nvBhg25HWprZMaPGeOlqxEjxGKz+XGRTAAmyJnq6sR370TXA2NLW+8HNjZ62dLOnaLrAQ1r2zmqPH482n0mTfJCKmEvCJHUooNZE/369Elct06kqiKsONRfulTEFDsX8QDlIa5nup9374pE8IiZHPY+ly+LZE/37/cM6mC6IB6Vl4urV6fzfUG6d0/csyf37wsXRFInaM4ckTjGdPg+apTYs6dI3RIWwH//1DV1qkiuxNY2FzrTd+2y6y8z2HQU6efZs+KBAyJZ4v+V0h6ArlwROaQP0uPH4ooV4sqV8Xz/4MF211M2wwoOq1mzRAq5Pnywa5+4KDHE9mI7ly0TO3fOvZ6/eZCoKwB32HS0SMFV1DNtImBKHYstBROoQ4fEQk2RaS+qrxejmj5M7NatIhWARS82xUJfAKahzFcdPnq0GLYgy7Rnbd8e6rGKRyzpuNzPBQty709RcNSZf/KkuHCh2GpMDyKbGNcLYE+YMkVks336NFx7XhTZ3szXiBaqtWvFuAOxM2dEZiyH8UErgc8JLNun7E0aFffSI7RP6owZmz9kSO73HjsmXr8ukppYsybSYyQvBp5QfOjQ3M9tRR496pGgLf1JtLlzRZJzlFzGp4SWDnUxFCrdvy+uWiWa3DJe3N69oj8uSEq8CER88uaNOGBAOv2ILGY69TBBJoM8O0t72zaRoztXBzlLlrT8XARW/IQq82JTMv3mKmv0/9CC4mJMYPwrMSETxAyurRUxQVmXP1fEid7mzeK3b+n2Jzb16CFu2SIWmtNJiriVxANsyq0uoCJfTk4G9y4t24/bSQ0rTkP6gVTG3mz//uKMGSK/ucId5Xe9lZUi5eMMLGUgz56J5Hxu3xZ50Xg3RMIltVn9BRja26PYsBHgAAAAAElFTkSuQmCC" alt="" style="pointer-events: none;" class="inline"/></a></p>
<h1><a class="anchor" id="autotoc_md6"></a>
Semantic search with a Retrieval-Augmented Generation (RAG) system</h1>
<p>LLM for Unity implements a super-fast similarity search functionality with a Retrieval-Augmented Generation (RAG) system.<br  />
 It is based on the LLM functionality, and the Approximate Nearest Neighbors (ANN) search from the <a href="https://github.com/unum-cloud/usearch">usearch</a> library.<br  />
 Semantic search works as follows.</p>
<p><b>Building the data</b> You provide text inputs (a phrase, paragraph, document) to add to the data.<br  />
 Each input is split into chunks (optional) and encoded into embeddings with a LLM.</p>
<p><b>Searching</b> You can then search for a query text input. <br  />
 The input is again encoded and the most similar text inputs or chunks in the data are retrieved.</p>
<p>To use semantic serch:</p><ul>
<li>create a GameObject for the LLM as described above. Download one of the provided RAG models or load your own (good options can be found at the <a href="https://huggingface.co/spaces/mteb/leaderboard">MTEB leaderboard</a>).</li>
<li>create an empty GameObject. In the GameObject Inspector click <code>Add Component</code> and select the <code>RAG</code> script.</li>
<li>In the Search Type dropdown of the RAG select your preferred search method. <code>SimpleSearch</code> is a simple brute-force search, while<code>DBSearch</code> is a fast ANN method that should be preferred in most cases.</li>
<li>In the Chunking Type dropdown of the RAG you can select a method for splitting the inputs into chunks. This is useful to have a more consistent meaning within each data part. Chunking methods for splitting according to tokens, words and sentences are provided.</li>
</ul>
<p>Alternatively, you can create the RAG from code (where llm is your LLM): </p><div class="fragment"><div class="line"><a class="code hl_class" href="classLLMUnity_1_1RAG.html">RAG</a> rag = gameObject.AddComponent&lt;<a class="code hl_class" href="classLLMUnity_1_1RAG.html">RAG</a>&gt;();</div>
<div class="line">rag.<a class="code hl_function" href="classLLMUnity_1_1RAG.html#a12f6d0345e9ee76a32b61e5f676fa945">Init</a>(<a class="code hl_enumeration" href="namespaceLLMUnity.html#a57c2884128df2e335455f2ba44e84e46">SearchMethods</a>.DBSearch, <a class="code hl_enumeration" href="namespaceLLMUnity.html#a8901dc84125a5c569f32e9991e846818">ChunkingMethods</a>.SentenceSplitter, llm);</div>
<div class="ttc" id="aclassLLMUnity_1_1RAG_html"><div class="ttname"><a href="classLLMUnity_1_1RAG.html">LLMUnity.RAG</a></div><div class="ttdoc">Class implementing a Retrieval Augmented Generation (RAG) system based on a search method and an opti...</div><div class="ttdef"><b>Definition</b> <a href="RAG_8cs_source.html#l00038">RAG.cs:39</a></div></div>
<div class="ttc" id="aclassLLMUnity_1_1RAG_html_a12f6d0345e9ee76a32b61e5f676fa945"><div class="ttname"><a href="classLLMUnity_1_1RAG.html#a12f6d0345e9ee76a32b61e5f676fa945">LLMUnity.RAG.Init</a></div><div class="ttdeci">void Init(SearchMethods searchMethod=SearchMethods.SimpleSearch, ChunkingMethods chunkingMethod=ChunkingMethods.NoChunking, LLM llm=null)</div><div class="ttdoc">Constructs the Retrieval Augmented Generation (RAG) system based on the provided search and chunking ...</div><div class="ttdef"><b>Definition</b> <a href="RAG_8cs_source.html#l00059">RAG.cs:59</a></div></div>
<div class="ttc" id="anamespaceLLMUnity_html_a57c2884128df2e335455f2ba44e84e46"><div class="ttname"><a href="namespaceLLMUnity.html#a57c2884128df2e335455f2ba44e84e46">LLMUnity.SearchMethods</a></div><div class="ttdeci">SearchMethods</div><div class="ttdoc">Search methods implemented in LLMUnity.</div><div class="ttdef"><b>Definition</b> <a href="RAG_8cs_source.html#l00014">RAG.cs:15</a></div></div>
<div class="ttc" id="anamespaceLLMUnity_html_a8901dc84125a5c569f32e9991e846818"><div class="ttname"><a href="namespaceLLMUnity.html#a8901dc84125a5c569f32e9991e846818">LLMUnity.ChunkingMethods</a></div><div class="ttdeci">ChunkingMethods</div><div class="ttdoc">Chunking methods implemented in LLMUnity.</div><div class="ttdef"><b>Definition</b> <a href="RAG_8cs_source.html#l00025">RAG.cs:26</a></div></div>
</div><!-- fragment --><p>In your script you can then use it as follows :unicorn:: </p><div class="fragment"><div class="line"><span class="keyword">using </span><a class="code hl_namespace" href="namespaceLLMUnity.html">LLMUnity</a>;</div>
<div class="line"> </div>
<div class="line"><span class="keyword">public</span> <span class="keyword">class </span>MyScript : MonoBehaviour</div>
<div class="line">{</div>
<div class="line">  <a class="code hl_class" href="classLLMUnity_1_1RAG.html">RAG</a> rag;</div>
<div class="line"> </div>
<div class="line">  async <span class="keywordtype">void</span> Game(){</div>
<div class="line">    ...</div>
<div class="line">    <span class="keywordtype">string</span>[] inputs = <span class="keyword">new</span> <span class="keywordtype">string</span>[]{</div>
<div class="line">      <span class="stringliteral">&quot;Hi! I&#39;m a search system.&quot;</span>,</div>
<div class="line">      <span class="stringliteral">&quot;the weather is nice. I like it.&quot;</span>,</div>
<div class="line">      <span class="stringliteral">&quot;I&#39;m a RAG system&quot;</span></div>
<div class="line">    };</div>
<div class="line">    <span class="comment">// add the inputs to the RAG</span></div>
<div class="line">    <span class="keywordflow">foreach</span> (<span class="keywordtype">string</span> input <span class="keywordflow">in</span> inputs) await rag.<a class="code hl_function" href="classLLMUnity_1_1Searchable.html#a5b3409ff27d91f45a77f5bf1e3249161">Add</a>(input);</div>
<div class="line">    <span class="comment">// get the 2 most similar inputs and their distance (dissimilarity) to the search query</span></div>
<div class="line">    (<span class="keywordtype">string</span>[] results, <span class="keywordtype">float</span>[] distances) = await rag.<a class="code hl_function" href="classLLMUnity_1_1Searchable.html#a2bae1bf1901381972408c63f4ee7d9dc">Search</a>(<span class="stringliteral">&quot;hello!&quot;</span>, 2);</div>
<div class="line">    <span class="comment">// to get the most similar text parts (chnuks) you can enable the returnChunks option</span></div>
<div class="line">    rag.<a class="code hl_function" href="classLLMUnity_1_1RAG.html#ac1082e5fb0cd8c98032ec02165c3ce26">ReturnChunks</a>(<span class="keyword">true</span>);</div>
<div class="line">    (results, distances) = await rag.<a class="code hl_function" href="classLLMUnity_1_1Searchable.html#a2bae1bf1901381972408c63f4ee7d9dc">Search</a>(<span class="stringliteral">&quot;hello!&quot;</span>, 2);</div>
<div class="line">    ...</div>
<div class="line">  }</div>
<div class="line">}</div>
<div class="ttc" id="aclassLLMUnity_1_1RAG_html_ac1082e5fb0cd8c98032ec02165c3ce26"><div class="ttname"><a href="classLLMUnity_1_1RAG.html#ac1082e5fb0cd8c98032ec02165c3ce26">LLMUnity.RAG.ReturnChunks</a></div><div class="ttdeci">void ReturnChunks(bool returnChunks)</div><div class="ttdoc">Set to true to return chunks or the direct input with the Search function.</div><div class="ttdef"><b>Definition</b> <a href="RAG_8cs_source.html#l00071">RAG.cs:71</a></div></div>
<div class="ttc" id="aclassLLMUnity_1_1Searchable_html_a2bae1bf1901381972408c63f4ee7d9dc"><div class="ttname"><a href="classLLMUnity_1_1Searchable.html#a2bae1bf1901381972408c63f4ee7d9dc">LLMUnity.Searchable.Search</a></div><div class="ttdeci">async Task&lt;(string[], float[])&gt; Search(string queryString, int k, string group=&quot;&quot;)</div><div class="ttdoc">Search for similar results to the provided query. The most similar results and their distances (dissi...</div><div class="ttdef"><b>Definition</b> <a href="Search_8cs_source.html#l00115">Search.cs:115</a></div></div>
<div class="ttc" id="aclassLLMUnity_1_1Searchable_html_a5b3409ff27d91f45a77f5bf1e3249161"><div class="ttname"><a href="classLLMUnity_1_1Searchable.html#a5b3409ff27d91f45a77f5bf1e3249161">LLMUnity.Searchable.Add</a></div><div class="ttdeci">Task&lt; int &gt; Add(string inputString, string group=&quot;&quot;)</div><div class="ttdoc">Adds a phrase to the search.</div></div>
</div><!-- fragment --><p>You can also add / search text inputs for groups of data e.g. for a specific character or scene: </p><div class="fragment"><div class="line">    <span class="comment">// add the inputs to the RAG for a group of data e.g. an orc character</span></div>
<div class="line">    <span class="keywordflow">foreach</span> (<span class="keywordtype">string</span> input <span class="keywordflow">in</span> inputs) await rag.<a class="code hl_function" href="classLLMUnity_1_1Searchable.html#a5b3409ff27d91f45a77f5bf1e3249161">Add</a>(input, <span class="stringliteral">&quot;orc&quot;</span>);</div>
<div class="line">    <span class="comment">// get the 2 most similar inputs for the group of data e.g. the orc character</span></div>
<div class="line">    (<span class="keywordtype">string</span>[] results, <span class="keywordtype">float</span>[] distances) = await rag.<a class="code hl_function" href="classLLMUnity_1_1Searchable.html#a2bae1bf1901381972408c63f4ee7d9dc">Search</a>(<span class="stringliteral">&quot;how do you feel?&quot;</span>, 2, <span class="stringliteral">&quot;orc&quot;</span>);</div>
<div class="line">...</div>
<div class="line"> </div>
<div class="line">You can save the <a class="code hl_class" href="classLLMUnity_1_1RAG.html">RAG</a> state (stored in the `Assets/StreamingAssets` folder):</div>
</div><!-- fragment --><p> {.cs} rag.Save("rag.zip"); </p><div class="fragment"><div class="line">and load it from disk:</div>
</div><!-- fragment --><p> {.cs} await rag.Load("rag.zip"); </p><div class="fragment"><div class="line">You can use the RAG to feed relevant data to the LLM based on a user message:</div>
</div><!-- fragment --><p> {.cs} string message = "How is the weather?"; (string[] similarPhrases, float[] distances) = await rag.Search(message, 3);</p>
<p>string prompt = "Answer the user query based on the provided data.

"; prompt += $"User query: {message}

"; prompt += $"Data:
"; foreach (string similarPhrase in similarPhrases) prompt += $"
- {similarPhrase}";</p>
<p>_ = llmCharacter.Chat(prompt, HandleReply, ReplyCompleted); ```</p>
<p>The <code>RAG</code> sample includes an example RAG implementation as well as an example RAG-LLM integration.</p>
<p>That's all :sparkles:!</p>
<h1><a class="anchor" id="autotoc_md7"></a>
LLM model management</h1>
<p>LLM for Unity uses a model manager that allows to load or download LLMs and ship them directly in your game.<br  />
 The model manager can be found as part of the LLM GameObject:<br  />
 <img src="images/LLM_manager.png" alt="" width="360" class="inline"/></p>
<p>You can download models with the <code>Download model</code> button.<br  />
 LLM for Unity includes different state of the art models built-in for different model sizes, quantised with the Q4_K_M method.<br  />
 Alternative models can be downloaded from <a href="https://huggingface.co/models?library=gguf&amp;sort=downloads">HuggingFace</a> in the .gguf format.<br  />
 You can download a model locally and load it with the <code>Load model</code> button, or copy the URL in the <code>Download model &gt; Custom URL</code> field to directly download it.<br  />
 If a HuggingFace model does not provide a gguf file, it can be converted to gguf with this <a href="https://huggingface.co/spaces/ggml-org/gguf-my-repo">online converter</a>.<br  />
</p>
<p>The chat template used for constructing the prompts is determined automatically from the model (if a relevant entry exists) or the model name. <br  />
 If incorrecly identified, you can select another template from the chat template dropdown.<br  />
 <br  />
 Models added in the model manager are copied to the game during the building process.<br  />
 You can omit a model from being built in by deselecting the "Build" checkbox.<br  />
 To remove the model (but not delete it from disk) you can click the bin button.<br  />
 The the path and URL (if downloaded) of each added model is diplayed in the expanded view of the model manager access with the <code>&gt;&gt;</code> button:<br  />
 <img src="images/LLM_manager_expanded.png" alt="" width="600" class="inline"/></p>
<p>You can create lighter builds by selecting the <code>Download on Build</code> option.<br  />
 Using this option the models will be downloaded the first time the game starts instead of copied in the build.<br  />
 If you have loaded a model locally you need to set its URL through the expanded view, otherwise it will be copied in the build.<br  />
</p>
<p>❕ Before using any model make sure you <b>check their license</b> ❕</p>
<h1><a class="anchor" id="autotoc_md8"></a>
Examples</h1>
<p>The <a href="https://github.com/undreamai/LLMUnity/tree/main/Samples~">Samples~</a> folder contains several examples of interaction 🤖:</p><ul>
<li><a href="https://github.com/undreamai/LLMUnity/tree/main/Samples~/SimpleInteraction">SimpleInteraction</a>: Simple interaction with an AI character</li>
<li><a href="https://github.com/undreamai/LLMUnity/tree/main/Samples~/MultipleCharacters">MultipleCharacters</a>: Simple interaction using multiple AI characters</li>
<li><a href="https://github.com/undreamai/LLMUnity/tree/main/Samples~/FunctionCalling">FunctionCalling</a>: Function calling sample with structured output from the LLM</li>
<li><a href="https://github.com/undreamai/LLMUnity/tree/main/Samples~/RAG">RAG</a>: Semantic search using a Retrieval Augmented Generation (RAG) system. Includes example using a RAG to feed information to a LLM</li>
<li><a href="https://github.com/undreamai/LLMUnity/tree/main/Samples~/MobileDemo">MobileDemo</a>: Example mobile app for Android / iOS with an initial screen displaying the model download progress</li>
<li><a href="https://github.com/undreamai/LLMUnity/tree/main/Samples~/ChatBot">ChatBot</a>: Interaction between a player and a AI with a UI similar to a messaging app (see image below)</li>
<li><a href="https://github.com/undreamai/LLMUnity/tree/main/Samples~/KnowledgeBaseGame">KnowledgeBaseGame</a>: Simple detective game using a knowledge base to provide information to the LLM based on <a href="https://github.com/google/mysteryofthreebots">google/mysteryofthreebots</a></li>
</ul>
<p><img src="images/demo.gif" alt="" width="400" class="inline"/></p>
<p>To install a sample:</p><ul>
<li>Open the Package Manager: <code>Window &gt; Package Manager</code></li>
<li>Select the <code>LLM for Unity</code> Package. From the <code>Samples</code> Tab, click <code>Import</code> next to the sample you want to install.</li>
</ul>
<p>The samples can be run with the <code>Scene.unity</code> scene they contain inside their folder.<br  />
 In the scene, select the <code>LLM</code> GameObject and click the <code>Download Model</code> button to download a default model or <code>Load model</code> to load your own model (see LLM model management).<br  />
 Save the scene, run and enjoy!</p>
<h1><a class="anchor" id="autotoc_md9"></a>
Options</h1>
<p>Details on the different parameters are provided as Unity Tooltips. Previous documentation can be found here (deprecated).</p>
<h1><a class="anchor" id="autotoc_md10"></a>
License</h1>
<p>The license of LLM for Unity is MIT (<a class="el" href="md_LICENSE.html">LICENSE.md</a>) and uses third-party software with MIT and Apache licenses. Some models included in the asset define their own license terms, please review them before using each model. Third-party licenses can be found in the (<a class="el" href="md_Third_01Party_01Notices.html">Third Party Notices.md</a>). </p>
</div></div><!-- PageDoc -->
<a href="doxygen_crawl.html"/>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.10.0 </li>
  </ul>
</div>
</body>
</html>
